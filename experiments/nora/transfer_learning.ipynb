{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aded33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import time\n",
    "\n",
    "# Torch libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff56ee",
   "metadata": {},
   "source": [
    "## EDA: \n",
    "Check if the image has a dog or not<br>\n",
    "If yes, count number of dogs/faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd543813",
   "metadata": {},
   "source": [
    "### Read a doggo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## REPLACE WITH YOUR NAME TO LOCATE FILES IN YOUR REPO ########################\n",
    "YOUR_NAME=\"nora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48edaffc",
   "metadata": {},
   "source": [
    "## Neural Nets\n",
    "(the OG way)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed79f12",
   "metadata": {},
   "source": [
    "**Sample annotations file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873bf8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xml.etree.ElementTree as ET\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Chihuahua\n",
    "# path = '../../dogs/Annotation/n02085620-Chihuahua/n02085620_10074'\n",
    "\n",
    "# with open(path) as annot_file:\n",
    "#     print(''.join(annot_file.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2e237",
   "metadata": {},
   "source": [
    "### 1. Using pre-trained image using `ImageNet` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ae6eb",
   "metadata": {},
   "source": [
    "#### Check if CUDA is available to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482955fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bac185",
   "metadata": {},
   "source": [
    "#### Create `labels` from Felix's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f69ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../dogs/Images')\n",
    "\n",
    "\n",
    "labels = []\n",
    "image_path = []\n",
    "label_num = []\n",
    "\n",
    "label_count = 0\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    if root!=\".\":\n",
    "        for name in files:\n",
    "    #         print(os.path.join(root, name))\n",
    "    #         print(root.split(\"-\",1)[1])\n",
    "\n",
    "            labels.append(root.split(\"-\",1)[1])\n",
    "            image_path.append(os.path.join(root, name))\n",
    "\n",
    "            if len(labels)>1 and labels[-1] != labels[-2]:\n",
    "                    label_count += 1\n",
    "\n",
    "            label_num.append(label_count)\n",
    "        \n",
    "\n",
    "df = pd.DataFrame({'labels':labels,'image_path':image_path, 'label_num':label_num}) \n",
    "\n",
    "# Create label dict for later use\n",
    "breeds = pd.Series(df.labels.values,index=df.label_num).to_dict()\n",
    "\n",
    "# saving the dataframe \n",
    "df.to_csv('../../experiments/nora/labels.csv') \n",
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88272172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test annotations\n",
    "# doggo_labels = pd.read_csv(\"../../experiments/\"+YOUR_NAME+\"/labels.csv\")\n",
    "# index = 400\n",
    "# print(\"Index: \", doggo_labels.iloc[index, 0], \"\\nLabel: \", doggo_labels.iloc[index, 1], \"\\nImage directory: \", doggo_labels.iloc[index, 2], \"\\nLabel number: \", doggo_labels.iloc[index, 3])\n",
    "\n",
    "# print(\"\\nTotal number of samples: \", doggo_labels.shape[0], \"\\nDog breeds/ unique labels: \", len(pd.unique(doggo_labels['labels'])))\n",
    "\n",
    "# # print(\"\\nBreed value counts:\", doggo_labels['labels'].value_counts())\n",
    "\n",
    "# print(\"\\nNumber images per breed \\nMax: \", max(doggo_labels['labels'].value_counts()), \"\\nMin:\", min(doggo_labels['labels'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, validate and test with proportional classes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "label_num = np.array(doggo_labels.iloc[:, 3])\n",
    "\n",
    "# labels\n",
    "dataY = label_num\n",
    "\n",
    "# features\n",
    "dataX_dummy = range(len(label_num)) \n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "index_train, index_test, y_train, y_test = train_test_split(dataX_dummy, dataY, test_size=1 - train_ratio, stratify=dataY)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "index_val, index_test, y_val, y_test = train_test_split(index_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ca44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check indices work\n",
    "img_annotations = pd.read_csv(\"../../experiments/\"+YOUR_NAME+\"/labels.csv\").iloc[index_train]\n",
    "display(img_annotations.head())\n",
    "print(img_annotations.iloc[0,2])\n",
    "print(img_annotations.iloc[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac9a15",
   "metadata": {},
   "source": [
    "#### Using same Dataset class and config as Felix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a2f7e",
   "metadata": {},
   "source": [
    "#### Different ways to optimize\n",
    "1. Optimal way to crop the image\n",
    "2. Changing number of channels - Grayscale, RGB, CMYK\n",
    "3. Normalize the tensor - either with 0s/1s or with mean/variance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836be0f9",
   "metadata": {},
   "source": [
    "**TODO:** Some images have channels > 4 which will cause issues while using the pre-trained ResNet50 model which is trained on images with 3 channels.<br>\n",
    "    \n",
    "_Ways to rectify:_<br>\n",
    "    1. Convert channel 4 to Grayscale (2)<br>\n",
    "    2. Convert Grayscale (2) to RBG (3)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db654008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoggoDataset(Dataset):\n",
    "    def __init__(self, indices, transform=None):\n",
    "        self.img_annotations = pd.read_csv(\"../../experiments/\"+YOUR_NAME+\"/labels.csv\").iloc[indices]\n",
    "        # Convert to Grayscale and crop it to 120x120\n",
    "        self.transform = transforms.Compose([\n",
    "#             transforms.Resize((120,120)),\n",
    "            transforms.CenterCrop(120),\n",
    "            # transforms.Grayscale(),\n",
    "#             transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor()\n",
    "            # transforms.Normalize((0, 0, 0),(1, 1, 1))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_annotations.iloc[idx, 2]\n",
    "        image = Image.open(img_path)\n",
    "        image = image.convert('RGB')\n",
    "        label = self.img_annotations.iloc[idx, 3]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec84161d",
   "metadata": {},
   "source": [
    "### `DataLoader()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d539e0",
   "metadata": {},
   "source": [
    "#### Adding an extra parameter `num_workers`\n",
    "\n",
    "`num_workers` can be decided based off of # of cores on the EC2 instance<br>\n",
    "**p2.xlarge** instance which has 4 CPU cores <br>\n",
    "**g4dn.2xlarge** instance which has 8 CPU cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229aa04",
   "metadata": {},
   "source": [
    "Doubling the `batch_size` to 128 since we're using CUDA on a GPU instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f64a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DoggoDataset(index_train)\n",
    "val_set = DoggoDataset(index_val)\n",
    "test_set = DoggoDataset(index_test)\n",
    "\n",
    "num_workers=4\n",
    "train_dataloader = DataLoader(train_set, batch_size=128, num_workers=num_workers, shuffle=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=128, num_workers=num_workers, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=128, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb35c8c",
   "metadata": {},
   "source": [
    "### Custom functions\n",
    "to make stuff modular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc55082c",
   "metadata": {},
   "source": [
    "#### 1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2016490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred, true):\n",
    "    # Converting pred to 0 or 1\n",
    "    pred = [1 if pred[i] >= 0.5 else 0 for i in range(len(pred))]\n",
    "    # Calculating accuracy by comparing predictions with true labels\n",
    "    acc = [1 if pred[i] == true[i] else 0 for i in range(len(pred))]\n",
    "    # Compute accuracy\n",
    "    acc = np.sum(acc) / len(pred)\n",
    "\n",
    "    \n",
    "    return (acc * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612dc61f",
   "metadata": {},
   "source": [
    "#### 2. Train the model over one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68173616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_dataloader):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for images, labels in train_dataloader:\n",
    "        \n",
    "        # ResNet is trained on images with only 3 channels\n",
    "        if(images.shape[1] == 3):\n",
    "            \n",
    "            # Load images and labels to device - in our case GPU!\n",
    "            images = images.to(device)\n",
    "            # print(images.shape)\n",
    "            labels = labels.to(device)\n",
    "            # print(labels.shape)\n",
    "#             labels = labels.reshape((1,labels.shape[0])) # [N, 1] - to match with preds shape\n",
    "            labels = labels.to(torch.long)\n",
    "        \n",
    "            # Reseting Gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            preds = model(images)\n",
    "            _, max_pred = torch.max(preds, 1)\n",
    "            pred_mat_tensor=torch.zeros( labels.shape[0], 120, device=device)\n",
    "            for index_num, label in enumerate(labels):\n",
    "                pred_mat_tensor[index_num, max_pred[index_num]]=1 #set to prediction value?\n",
    "            pred_mat_tensor=pred_mat_tensor\n",
    "#             pred_mat_tensor[max_pred, ]\n",
    "#             other_preds=other_preds.reshape((other_preds.shape[0],1)).to(torch.float32)\n",
    "\n",
    "#             print(\"------------------------------------\")\n",
    "            pred_mat_tensor.requires_grad_()\n",
    "    \n",
    "            # Calculating Loss\n",
    "            _loss = criterion(preds, labels)\n",
    "            loss = _loss.item()\n",
    "            epoch_loss.append(loss)\n",
    "\n",
    "            # Calculating Accuracy\n",
    "            acc = get_accuracy(max_pred, labels)\n",
    "            epoch_acc.append(acc)\n",
    "\n",
    "            # Backward\n",
    "            _loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Overall Epoch Results\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Acc and Loss\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    epoch_acc = np.mean(epoch_acc)\n",
    "    \n",
    "    # Log the results\n",
    "    train_logs[\"loss\"].append(epoch_loss)\n",
    "    train_logs[\"accuracy\"].append(epoch_acc)\n",
    "    train_logs[\"time\"].append(total_time)\n",
    "        \n",
    "    return epoch_loss, epoch_acc, total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a575c88",
   "metadata": {},
   "source": [
    "#### 3. Validate the model over one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc98c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_one_epoch(val_dataloader, best_val_acc):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for images, labels in val_dataloader:\n",
    "        \n",
    "        # ResNet is trained on images with only 3 channels\n",
    "        if(images.shape[1] == 3):\n",
    "        \n",
    "            # Load images and labels to device - again GPU!\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "#             labels = labels.reshape((1,labels.shape[0])) # [N, 1] - to match with preds shape\n",
    "            labels = labels.to(torch.long)\n",
    "\n",
    "            # Forward\n",
    "            preds = model(images)\n",
    "            _, max_pred = torch.max(preds, 1)\n",
    "\n",
    "            pred_mat_tensor=torch.zeros( labels.shape[0], 120, device=device)\n",
    "            for index_num, label in enumerate(labels):\n",
    "                pred_mat_tensor[index_num, max_pred[index_num]]=1 # change probably\n",
    "                \n",
    "\n",
    "#             pred_mat_tensor[max_pred, ]\n",
    "#             other_preds=other_preds.reshape((other_preds.shape[0],1)).to(torch.float32)\n",
    "\n",
    "            pred_mat_tensor.requires_grad_()\n",
    "            # Calculating Loss\n",
    "            _loss = criterion(preds, labels)\n",
    "            loss = _loss.item()\n",
    "            epoch_loss.append(loss)\n",
    "\n",
    "            # Calculating Accuracy\n",
    "            acc = get_accuracy(max_pred, labels)\n",
    "            epoch_acc.append(acc)\n",
    "    \n",
    "    # Overall Epoch Results\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Acc and Loss\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    epoch_acc = np.mean(epoch_acc)\n",
    "    \n",
    "    # Log the results\n",
    "    val_logs[\"loss\"].append(epoch_loss)\n",
    "    val_logs[\"accuracy\"].append(epoch_acc)\n",
    "    val_logs[\"time\"].append(total_time)\n",
    "    \n",
    "    # Save the best model\n",
    "    if epoch_acc > best_val_acc:\n",
    "        best_val_acc = epoch_acc\n",
    "        torch.save(model.state_dict(),\"resnet50_best.pth\")\n",
    "        \n",
    "    return epoch_loss, epoch_acc, total_time, best_val_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc384bc",
   "metadata": {},
   "source": [
    "## `ResNet50`\n",
    "Let's gooooooo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(pretrained = True)\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 120, bias = True),\n",
    "    nn.Softmax()\n",
    ")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15920b",
   "metadata": {},
   "source": [
    "#### Model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Logs\n",
    "train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
    "val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
    "\n",
    "# Loading model to device\n",
    "model.to(device)\n",
    "\n",
    "# No of epochs \n",
    "epochs = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5c274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_val_acc = 0 # this will be computed in the validation step\n",
    "optimizer.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "#     print(epoch)\n",
    "    # Training\n",
    "    loss, acc, _time = train_one_epoch(train_dataloader)\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"\\nTraining\")\n",
    "    print(\"Epoch {}\".format(epoch+1))\n",
    "    print(\"Loss : {}\".format(round(loss, 4)))\n",
    "    print(\"Acc : {}\".format(round(acc, 4)))\n",
    "    print(\"Time : {}\".format(round(_time, 4)))\n",
    "    \n",
    "    # Validation\n",
    "    loss, acc, _time, best_val_acc = val_one_epoch(val_dataloader, best_val_acc)\n",
    "    \n",
    "    print(\"\\nValidating\")\n",
    "    print(\"Epoch {}\".format(epoch+1))\n",
    "    print(\"Loss : {}\".format(round(loss, 4)))\n",
    "    print(\"Acc : {}\".format(round(acc, 4)))\n",
    "    print(\"Time : {}\".format(round(_time, 4)))\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37402a7b",
   "metadata": {},
   "source": [
    "# Testing Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b750a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_dataloader):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for images, labels in test_dataloader:\n",
    "        \n",
    "        # ResNet is trained on images with only 3 channels\n",
    "        if(images.shape[1] == 3):\n",
    "            \n",
    "            # Load images and labels to device - in our case GPU!\n",
    "            images = images.to(device)\n",
    "            # print(images.shape)\n",
    "            labels = labels.to(device)\n",
    "            # print(labels.shape)\n",
    "#             labels = labels.reshape((1,labels.shape[0])) # [N, 1] - to match with preds shape\n",
    "            labels = labels.to(torch.long)\n",
    "        \n",
    "            # Reseting Gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            preds = model(images)\n",
    "            _, max_pred = torch.max(preds, 1)\n",
    "#             print(max_pred.shape)\n",
    "#             print(max_pred)\n",
    "            pred_mat_tensor=torch.zeros( labels.shape[0], 120, device=device)\n",
    "            for index_num, label in enumerate(labels):\n",
    "                pred_mat_tensor[index_num, max_pred[index_num]]=1\n",
    "            pred_mat_tensor=pred_mat_tensor\n",
    "\n",
    "#             pred_mat_tensor.requires_grad_()\n",
    "\n",
    "            acc = get_accuracy(max_pred, labels)\n",
    "        return pred_mat_tensor, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f6dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_mat_tensor, test_labels=test_model(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d45ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ,max_pred_label=torch.max(test_pred_mat_tensor, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f072ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac5289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels==max_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90983f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc8da3",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "1. Dockerize the entire codebase\n",
    "2. Use Tensorflow serving to fetch the latest trained model instead of training every time\n",
    "3. Compare the performance of ResNet34, VGG-16 and a few more architectures with ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26173a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6222bac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40074596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5bdfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee9d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
