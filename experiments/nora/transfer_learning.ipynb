{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60525c72",
   "metadata": {},
   "source": [
    "# Transfer Learning: Dog Breed Classifier\n",
    "Creation Date: March 2022\n",
    "    \n",
    "Edit Date: March 30, 2022 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a537cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import time\n",
    "\n",
    "# Torch libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1125d650",
   "metadata": {},
   "source": [
    "### Goals for Next Meeting on April 6 ,2022\n",
    "- synthetic data\n",
    "- transforms\n",
    "- create df for an experiment log\n",
    "- train with other models (cnn type)\n",
    "\n",
    "\n",
    "### Longterm:\n",
    "- try transformers arch\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81313a95",
   "metadata": {},
   "source": [
    "## EDA: \n",
    "Check if the image has a dog or not<br>\n",
    "If yes, count number of dogs/faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75d61b5",
   "metadata": {},
   "source": [
    "### Read a doggo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## REPLACE WITH YOUR NAME TO LOCATE FILES IN YOUR REPO ########################\n",
    "YOUR_NAME=\"nora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742fa121",
   "metadata": {},
   "source": [
    "## Neural Nets\n",
    "(the OG way)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f8241",
   "metadata": {},
   "source": [
    "### 1. Using pre-trained image using `ImageNet` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e112a984",
   "metadata": {},
   "source": [
    "#### Check if CUDA is available to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51afa021",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9f9ca8",
   "metadata": {},
   "source": [
    "#### Create `labels` from Felix's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4222bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../dogs/Images')\n",
    "\n",
    "\n",
    "labels = []\n",
    "image_path = []\n",
    "label_num = []\n",
    "\n",
    "label_count = 0\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    if root!=\".\":\n",
    "        for name in files:\n",
    "    #         print(os.path.join(root, name))\n",
    "    #         print(root.split(\"-\",1)[1])\n",
    "\n",
    "            labels.append(root.split(\"-\",1)[1])\n",
    "            image_path.append(os.path.join(root, name))\n",
    "\n",
    "            if len(labels)>1 and labels[-1] != labels[-2]:\n",
    "                    label_count += 1\n",
    "\n",
    "            label_num.append(label_count)\n",
    "        \n",
    "\n",
    "df = pd.DataFrame({'labels':labels,'image_path':image_path, 'label_num':label_num}) \n",
    "\n",
    "# Create label dict for later use\n",
    "breeds = pd.Series(df.labels.values,index=df.label_num).to_dict()\n",
    "\n",
    "# saving the dataframe \n",
    "df.to_csv('../../experiments/'+YOUR_NAME+'/labels.csv') \n",
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f14f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test annotations\n",
    "doggo_labels = pd.read_csv(\"../../experiments/\"+YOUR_NAME+\"/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe75872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, validate and test with proportional classes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "label_num = np.array(doggo_labels.iloc[:, 3])\n",
    "\n",
    "# labels\n",
    "dataY = label_num\n",
    "\n",
    "# features\n",
    "dataX_dummy = range(len(label_num)) \n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "index_train, index_test, y_train, y_test = train_test_split(dataX_dummy, dataY, test_size=1 - train_ratio, stratify=dataY)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "index_val, index_test, y_val, y_test = train_test_split(index_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee6f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check indices work\n",
    "# img_annotations = pd.read_csv(\"../../experiments/\"+YOUR_NAME+\"/labels.csv\").iloc[index_train]\n",
    "# display(img_annotations.head())\n",
    "# print(img_annotations.iloc[0,2])\n",
    "# print(img_annotations.iloc[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d952219f",
   "metadata": {},
   "source": [
    "#### Using same Dataset class and config as Felix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a234f2",
   "metadata": {},
   "source": [
    "#### Different ways to optimize\n",
    "1. Optimal way to crop the image\n",
    "2. Changing number of channels - Grayscale, RGB, CMYK\n",
    "3. Normalize the tensor - either with 0s/1s or with mean/variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ab238",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoggoDataset(Dataset):\n",
    "    def __init__(self, indices, transform=None):\n",
    "        self.img_annotations = pd.read_csv(\"../../experiments/\"+YOUR_NAME+\"/labels.csv\").iloc[indices]\n",
    "        # Convert to Grayscale and crop it to 120x120\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((120,120)), # Dan's is different\n",
    "#             transforms.CenterCrop(120),\n",
    "            # transforms.Grayscale(),\n",
    "#             transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize((0, 0, 0),(1, 1, 1))\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) #these values come from ImageNet Dataset mean and std (resnet50 trained on ImageNet)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_annotations.iloc[idx, 2]\n",
    "        image = Image.open(img_path)\n",
    "        image = image.convert('RGB')\n",
    "        label = self.img_annotations.iloc[idx, 3]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da60ba0",
   "metadata": {},
   "source": [
    "### `DataLoader()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170d32ed",
   "metadata": {},
   "source": [
    "#### Adding an extra parameter `num_workers`\n",
    "\n",
    "`num_workers` can be decided based off of # of cores on the EC2 instance<br>\n",
    "**p2.xlarge** instance which has 4 CPU cores <br>\n",
    "**g4dn.2xlarge** instance which has 8 CPU cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f24b4",
   "metadata": {},
   "source": [
    "Doubling the `batch_size` to 128 since we're using CUDA on a GPU instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7452dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DoggoDataset(index_train)\n",
    "val_set = DoggoDataset(index_val)\n",
    "test_set = DoggoDataset(index_test)\n",
    "\n",
    "num_workers=4\n",
    "train_dataloader = DataLoader(train_set, batch_size=128, num_workers=num_workers, shuffle=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=128, num_workers=num_workers, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=128, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f66510",
   "metadata": {},
   "source": [
    "### Custom functions\n",
    "to make stuff modular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef2479",
   "metadata": {},
   "source": [
    "#### 1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4889712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred, true):\n",
    "    # Calculating accuracy by comparing predictions with true labels\n",
    "    acc = [1 if pred[i] == true[i] else 0 for i in range(len(pred))]\n",
    "    # Compute accuracy\n",
    "    acc = np.sum(acc) / len(pred)\n",
    "\n",
    "    \n",
    "    return acc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457e8fba",
   "metadata": {},
   "source": [
    "#### 2. Train the model over one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_dataloader):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    for images, labels in train_dataloader:\n",
    "        \n",
    "        # ResNet is trained on images with only 3 channels\n",
    "        if(images.shape[1] == 3):\n",
    "            \n",
    "            # Load images and labels to device - in our case GPU!\n",
    "            images = images.to(device)\n",
    "            # print(images.shape)\n",
    "            labels = labels.to(device)\n",
    "            # print(labels.shape)\n",
    "#             labels = labels.reshape((1,labels.shape[0])) # [N, 1] - to match with preds shape\n",
    "            labels = labels.to(torch.long)\n",
    "        \n",
    "            # Reseting Gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            with torch.set_grad_enabled(True):\n",
    "                preds = model(images)\n",
    "                _, max_pred = torch.max(preds, 1)\n",
    "\n",
    "\n",
    "            # Calculating Loss\n",
    "            _loss = criterion(preds, labels)\n",
    "            loss = _loss.item()\n",
    "            epoch_loss.append(loss)\n",
    "\n",
    "            # Calculating Accuracy\n",
    "            acc = get_accuracy(max_pred, labels)\n",
    "            epoch_acc.append(acc)\n",
    "\n",
    "            # Backward\n",
    "            _loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    lr_scheduler.step()\n",
    "    # Overall Epoch Results\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Acc and Loss\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    epoch_acc = np.mean(epoch_acc)\n",
    "    \n",
    "    # Log the results\n",
    "    train_logs[\"loss\"].append(epoch_loss)\n",
    "    train_logs[\"accuracy\"].append(epoch_acc)\n",
    "    train_logs[\"time\"].append(total_time)\n",
    "        \n",
    "    return epoch_loss, epoch_acc, total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f918c54",
   "metadata": {},
   "source": [
    "#### 3. Validate the model over one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9bd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_one_epoch(val_dataloader, best_val_acc):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    start_time = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    for images, labels in val_dataloader:\n",
    "        \n",
    "        # ResNet is trained on images with only 3 channels\n",
    "        if(images.shape[1] == 3):\n",
    "        \n",
    "            # Load images and labels to device - again GPU!\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "#             labels = labels.reshape((1,labels.shape[0])) # [N, 1] - to match with preds shape\n",
    "            labels = labels.to(torch.long)\n",
    "\n",
    "            # Forward\n",
    "            preds = model(images)\n",
    "            _, max_pred = torch.max(preds, 1)\n",
    "            \n",
    "            # Calculating Loss\n",
    "            _loss = criterion(preds, labels)\n",
    "            loss = _loss.item()\n",
    "            epoch_loss.append(loss)\n",
    "\n",
    "            # Calculating Accuracy\n",
    "            acc = get_accuracy(max_pred, labels)\n",
    "            epoch_acc.append(acc)\n",
    "    \n",
    "    # Overall Epoch Results\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Acc and Loss\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    epoch_acc = np.mean(epoch_acc)\n",
    "    \n",
    "    # Log the results\n",
    "    val_logs[\"loss\"].append(epoch_loss)\n",
    "    val_logs[\"accuracy\"].append(epoch_acc)\n",
    "    val_logs[\"time\"].append(total_time)\n",
    "    \n",
    "    # Save the best model\n",
    "    if epoch_acc > best_val_acc:\n",
    "        best_val_acc = epoch_acc\n",
    "        torch.save(model.state_dict(),\"resnet50_best.pth\")\n",
    "        \n",
    "    return epoch_loss, epoch_acc, total_time, best_val_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3630ef5",
   "metadata": {},
   "source": [
    "## `ResNet50`\n",
    "Let's gooooooo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61be1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(pretrained = True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Linear(num_ftrs, 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a011d6a6",
   "metadata": {},
   "source": [
    "#### Model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace22ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) #step_size = 5, gamma = 0.5)\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Logs\n",
    "train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
    "val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
    "\n",
    "# Loading model to device\n",
    "model.to(device)\n",
    "\n",
    "# No of epochs \n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca9365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_val_acc = 0 # this will be computed in the validation step\n",
    "optimizer.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "#     print(epoch)\n",
    "    # Training\n",
    "    loss, acc, _time = train_one_epoch(train_dataloader)\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"\\nTraining\")\n",
    "    print(\"Epoch {}\".format(epoch+1))\n",
    "    print(\"Loss : {}\".format(round(loss, 4)))\n",
    "    print(\"Acc : {}\".format(round(acc, 4)))\n",
    "    print(\"Time : {}\".format(round(_time, 4)))\n",
    "    \n",
    "    # Validation\n",
    "    loss, acc, _time, best_val_acc = val_one_epoch(val_dataloader, best_val_acc)\n",
    "    \n",
    "    print(\"\\nValidating\")\n",
    "    print(\"Epoch {}\".format(epoch+1))\n",
    "    print(\"Loss : {}\".format(round(loss, 4)))\n",
    "    print(\"Acc : {}\".format(round(acc, 4)))\n",
    "    print(\"Time : {}\".format(round(_time, 4)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f6037",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "#### Without Normalization\n",
    "--------------------------------\n",
    "\n",
    "Training\n",
    "Epoch 50\n",
    "Loss : 2.1048\n",
    "Acc : 0.5613\n",
    "Time : 20.1817\n",
    "\n",
    "Validating\n",
    "Epoch 50\n",
    "Loss : 2.1804\n",
    "Acc : 0.5199\n",
    "Time : 4.4254\n",
    "\n",
    "\n",
    "#### With Normalization\n",
    "--------------------------------\n",
    "\n",
    "Training\n",
    "Epoch 50\n",
    "Loss : 2.0568\n",
    "Acc : 0.5753\n",
    "Time : 20.5044\n",
    "\n",
    "Validating\n",
    "Epoch 50\n",
    "Loss : 2.1682\n",
    "Acc : 0.518\n",
    "Time : 4.6709\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec3311",
   "metadata": {},
   "source": [
    "# Testing Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ed90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_dataloader):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for images, labels in test_dataloader:\n",
    "        \n",
    "        # ResNet is trained on images with only 3 channels\n",
    "        if(images.shape[1] == 3):\n",
    "            \n",
    "            # Load images and labels to device - in our case GPU!\n",
    "            images = images.to(device)\n",
    "            # print(images.shape)\n",
    "            labels = labels.to(device)\n",
    "            # print(labels.shape)\n",
    "#             labels = labels.reshape((1,labels.shape[0])) # [N, 1] - to match with preds shape\n",
    "            labels = labels.to(torch.long)\n",
    "        \n",
    "\n",
    "            # Forward\n",
    "            preds = model(images)\n",
    "            _, max_pred = torch.max(preds, 1)\n",
    "\n",
    "            acc = get_accuracy(max_pred, labels)\n",
    "        return preds, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tensor, test_labels=test_model(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,max_pred_label=torch.max(pred_tensor, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ce21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_labels==max_pred_label).sum()/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e828efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label number to dog breed name dictionary\n",
    "label_num_to_label_name_dict=doggo_labels[[\"labels\", \"label_num\"]].drop_duplicates().set_index(\"label_num\").to_dict(orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef31de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, test_dataloader, label_num_to_label_name_dict, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(test_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'PREDICTED: {label_num_to_label_name_dict[int(preds[j].cpu().numpy() )][\"labels\"]}, LABEL: {label_num_to_label_name_dict[int(labels[j].cpu().numpy())][\"labels\"]}')\n",
    "                inp=inputs.cpu().data[j]\n",
    "                inp = inp.numpy().transpose((1, 2, 0))\n",
    "                ##### remove/change this block if not using normalization/normalization values change #####\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                inp = std * inp + mean\n",
    "                ##########################################################################################\n",
    "                plt.imshow(inp)\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb54d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, test_dataloader, label_num_to_label_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(),f\"../../experiments/{YOUR_NAME}/resnet50_best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d603452",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "1. Dockerize the entire codebase\n",
    "2. Use Tensorflow serving to fetch the latest trained model instead of training every time\n",
    "3. Compare the performance of ResNet34, VGG-16 and a few more architectures with ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17590121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
