{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d3ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The task is to use Word embeddings in Spacy\n",
    "#Spacy is a natural language processing library for Python designed to have fast performance\n",
    "#Spacy is a free, open-source library for NLP in Python \n",
    "#and provides pre-trained word vectors(set of numbers) or word embedding models built in. \n",
    "#Downloaded a pre-defined model \n",
    "#python -m spacy download en_core_web_lg\n",
    "#Itâ€™s a quick and easy technique for learning numberical representation of words\n",
    "#word2vec - it is a technique which allows you to do mathematics with a word \n",
    "#(basically assign vector of numbers to a word)\n",
    "\n",
    "#Gensim is a topic modelling library for Python that provides modules for training Word2Vec and other word embedding algorithms, and allows using pre-trained models.\n",
    "import os\n",
    "from os import listdir\n",
    "import time\n",
    "import gzip\n",
    "import json \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import metrics\n",
    "\n",
    "import spacy\n",
    "# Torch libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d98b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "021b7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a594ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getDF('Luxury_Beauty_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f57228b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 34278 entries, 0 to 34277\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   overall         34278 non-null  float64\n",
      " 1   verified        34278 non-null  bool   \n",
      " 2   reviewTime      34278 non-null  object \n",
      " 3   reviewerID      34278 non-null  object \n",
      " 4   asin            34278 non-null  object \n",
      " 5   style           16841 non-null  object \n",
      " 6   reviewerName    34278 non-null  object \n",
      " 7   reviewText      34265 non-null  object \n",
      " 8   summary         34263 non-null  object \n",
      " 9   unixReviewTime  34278 non-null  int64  \n",
      " 10  vote            6532 non-null   object \n",
      " 11  image           617 non-null    object \n",
      "dtypes: bool(1), float64(1), int64(1), object(9)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#No. of reviews/counts per rating\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fe96820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>01 5, 2018</td>\n",
       "      <td>A2HOI48JK8838M</td>\n",
       "      <td>B00004U9V2</td>\n",
       "      <td>{'Size:': ' 0.9 oz.'}</td>\n",
       "      <td>DB</td>\n",
       "      <td>This handcream has a beautiful fragrance. It d...</td>\n",
       "      <td>Beautiful Fragrance</td>\n",
       "      <td>1515110400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 5, 2017</td>\n",
       "      <td>A1YIPEY7HX73S7</td>\n",
       "      <td>B00004U9V2</td>\n",
       "      <td>{'Size:': ' 3.5 oz.'}</td>\n",
       "      <td>Ajaey</td>\n",
       "      <td>wonderful hand lotion, for seriously dry skin,...</td>\n",
       "      <td>wonderful hand lotion</td>\n",
       "      <td>1491350400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 27, 2017</td>\n",
       "      <td>A2QCGHIJ2TCLVP</td>\n",
       "      <td>B00004U9V2</td>\n",
       "      <td>{'Size:': ' 250 g'}</td>\n",
       "      <td>D. Jones</td>\n",
       "      <td>Best hand cream around.  Silky, thick, soaks i...</td>\n",
       "      <td>Best hand cream around</td>\n",
       "      <td>1490572800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 20, 2017</td>\n",
       "      <td>A2R4UNHFJBA6PY</td>\n",
       "      <td>B00004U9V2</td>\n",
       "      <td>{'Size:': ' 3.5 oz.'}</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Thanks!!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1489968000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 28, 2017</td>\n",
       "      <td>A2QCGHIJ2TCLVP</td>\n",
       "      <td>B00004U9V2</td>\n",
       "      <td>{'Size:': ' 0.9 oz.'}</td>\n",
       "      <td>D. Jones</td>\n",
       "      <td>Great hand lotion.  Soaks right in and leaves ...</td>\n",
       "      <td>Great hand lotion!</td>\n",
       "      <td>1488240000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 25, 2017</td>\n",
       "      <td>A1606LA683WZZU</td>\n",
       "      <td>B00004U9V2</td>\n",
       "      <td>{'Size:': ' 250 g'}</td>\n",
       "      <td>Amr</td>\n",
       "      <td>Great product. Doesn't leave you hands feeling...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1487980800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 25, 2017</td>\n",
       "      <td>A1606LA683WZZU</td>\n",
       "      <td>B00004U9V2</td>\n",
       "      <td>{'Size:': ' 3.5 oz.'}</td>\n",
       "      <td>Amr</td>\n",
       "      <td>Great product. Doesn't leave you hands feeling...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1487980800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>01 30, 2017</td>\n",
       "      <td>A1606LA683WZZU</td>\n",
       "      <td>B00004U9V2</td>\n",
       "      <td>{'Size:': ' 0.9 oz.'}</td>\n",
       "      <td>Amr</td>\n",
       "      <td>Just as described. Arrived on time.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1485734400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>01 24, 2017</td>\n",
       "      <td>A1YY53NQXFKMRN</td>\n",
       "      <td>B00004U9V2</td>\n",
       "      <td>{'Size:': ' 3.5 oz.'}</td>\n",
       "      <td>Trixie</td>\n",
       "      <td>Nice lightweight hand cream for the summer.</td>\n",
       "      <td>Smells good, absorbs quickly</td>\n",
       "      <td>1485216000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12 1, 2016</td>\n",
       "      <td>A3R0NQ9E53JHYQ</td>\n",
       "      <td>B00004U9V2</td>\n",
       "      <td>{'Size:': ' 250 g'}</td>\n",
       "      <td>T. Hooth</td>\n",
       "      <td>Best hand cream ever.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1480550400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0      5.0      True   01 5, 2018  A2HOI48JK8838M  B00004U9V2   \n",
       "1      5.0      True   04 5, 2017  A1YIPEY7HX73S7  B00004U9V2   \n",
       "2      5.0      True  03 27, 2017  A2QCGHIJ2TCLVP  B00004U9V2   \n",
       "3      5.0      True  03 20, 2017  A2R4UNHFJBA6PY  B00004U9V2   \n",
       "4      5.0      True  02 28, 2017  A2QCGHIJ2TCLVP  B00004U9V2   \n",
       "5      5.0      True  02 25, 2017  A1606LA683WZZU  B00004U9V2   \n",
       "6      5.0      True  02 25, 2017  A1606LA683WZZU  B00004U9V2   \n",
       "7      5.0      True  01 30, 2017  A1606LA683WZZU  B00004U9V2   \n",
       "8      4.0     False  01 24, 2017  A1YY53NQXFKMRN  B00004U9V2   \n",
       "9      5.0      True   12 1, 2016  A3R0NQ9E53JHYQ  B00004U9V2   \n",
       "\n",
       "                   style     reviewerName  \\\n",
       "0  {'Size:': ' 0.9 oz.'}               DB   \n",
       "1  {'Size:': ' 3.5 oz.'}            Ajaey   \n",
       "2    {'Size:': ' 250 g'}         D. Jones   \n",
       "3  {'Size:': ' 3.5 oz.'}  Amazon Customer   \n",
       "4  {'Size:': ' 0.9 oz.'}         D. Jones   \n",
       "5    {'Size:': ' 250 g'}              Amr   \n",
       "6  {'Size:': ' 3.5 oz.'}              Amr   \n",
       "7  {'Size:': ' 0.9 oz.'}              Amr   \n",
       "8  {'Size:': ' 3.5 oz.'}           Trixie   \n",
       "9    {'Size:': ' 250 g'}         T. Hooth   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  This handcream has a beautiful fragrance. It d...   \n",
       "1  wonderful hand lotion, for seriously dry skin,...   \n",
       "2  Best hand cream around.  Silky, thick, soaks i...   \n",
       "3                                           Thanks!!   \n",
       "4  Great hand lotion.  Soaks right in and leaves ...   \n",
       "5  Great product. Doesn't leave you hands feeling...   \n",
       "6  Great product. Doesn't leave you hands feeling...   \n",
       "7                Just as described. Arrived on time.   \n",
       "8        Nice lightweight hand cream for the summer.   \n",
       "9                              Best hand cream ever.   \n",
       "\n",
       "                        summary  unixReviewTime vote image  \n",
       "0           Beautiful Fragrance      1515110400  NaN   NaN  \n",
       "1         wonderful hand lotion      1491350400  NaN   NaN  \n",
       "2        Best hand cream around      1490572800  NaN   NaN  \n",
       "3                    Five Stars      1489968000  NaN   NaN  \n",
       "4            Great hand lotion!      1488240000  NaN   NaN  \n",
       "5                    Five Stars      1487980800  NaN   NaN  \n",
       "6                    Five Stars      1487980800  NaN   NaN  \n",
       "7                    Five Stars      1485734400  NaN   NaN  \n",
       "8  Smells good, absorbs quickly      1485216000  NaN   NaN  \n",
       "9                    Five Stars      1480550400  NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7e02f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34268</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>08 21, 2018</td>\n",
       "      <td>A1ID5QT86H8J9D</td>\n",
       "      <td>B01GOZ61O8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JSM</td>\n",
       "      <td>Love it.  Just wish it came it bigger tube.  I...</td>\n",
       "      <td>Great SPF!</td>\n",
       "      <td>1534809600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34269</th>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>05 21, 2018</td>\n",
       "      <td>A1G60ANYI0HMEU</td>\n",
       "      <td>B01GOZ61O8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeddy 3</td>\n",
       "      <td>I really like the Tizo sunscreens, but this on...</td>\n",
       "      <td>Not sure what else it's doing, but it's defini...</td>\n",
       "      <td>1526860800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34270</th>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>12 10, 2017</td>\n",
       "      <td>ATN4J5VS8Q0YM</td>\n",
       "      <td>B01GOZ61O8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anna Hope</td>\n",
       "      <td>I used this on a recent trip across the countr...</td>\n",
       "      <td>Not Everyday</td>\n",
       "      <td>1512864000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34271</th>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10 10, 2017</td>\n",
       "      <td>AVL5IDEE8YA3D</td>\n",
       "      <td>B01GOZ61O8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rachel McElhany</td>\n",
       "      <td>This product doesn't really say what it is. Th...</td>\n",
       "      <td>TIZO AM Replenish</td>\n",
       "      <td>1507593600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34272</th>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>09 9, 2017</td>\n",
       "      <td>A2X2WTEVCZ5L8N</td>\n",
       "      <td>B01GOZ61O8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sandy Kay</td>\n",
       "      <td>I'm not sure whether it is the ceramicides or ...</td>\n",
       "      <td>Hated how it felt on my face</td>\n",
       "      <td>1504915200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34273</th>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>09 3, 2017</td>\n",
       "      <td>A2CF66KIQ3RKX3</td>\n",
       "      <td>B01GOZ61O8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vivian Deliz</td>\n",
       "      <td>I like to use moisturizers and sunscreens that...</td>\n",
       "      <td>Works great as a moisturizer and sunscreen</td>\n",
       "      <td>1504396800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34274</th>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>09 3, 2017</td>\n",
       "      <td>A1LKOIZXPQ9VG0</td>\n",
       "      <td>B01GOZ61O8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elisa 20</td>\n",
       "      <td>I wouldn't be able to afford this if not asked...</td>\n",
       "      <td>Nice skin care product and sunscreen if you do...</td>\n",
       "      <td>1504396800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34275</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>08 25, 2017</td>\n",
       "      <td>AV2RWORXTFRJU</td>\n",
       "      <td>B01H353HUY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gapeachmama</td>\n",
       "      <td>Did nothing</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1503619200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34276</th>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>07 8, 2017</td>\n",
       "      <td>A22S7D0LP8GRDH</td>\n",
       "      <td>B01H353HUY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jacob and Kiki Hantla</td>\n",
       "      <td>I love the Oribe bright blonde radiance spray....</td>\n",
       "      <td>No more brass!</td>\n",
       "      <td>1499472000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34277</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 9, 2018</td>\n",
       "      <td>AAF5D1LTFGB7L</td>\n",
       "      <td>B01HGSJPMW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Libby Johnson</td>\n",
       "      <td>I love all of the Elemis products.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1531094400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall  verified   reviewTime      reviewerID        asin style  \\\n",
       "34268      5.0      True  08 21, 2018  A1ID5QT86H8J9D  B01GOZ61O8   NaN   \n",
       "34269      4.0     False  05 21, 2018  A1G60ANYI0HMEU  B01GOZ61O8   NaN   \n",
       "34270      3.0     False  12 10, 2017   ATN4J5VS8Q0YM  B01GOZ61O8   NaN   \n",
       "34271      4.0     False  10 10, 2017   AVL5IDEE8YA3D  B01GOZ61O8   NaN   \n",
       "34272      2.0     False   09 9, 2017  A2X2WTEVCZ5L8N  B01GOZ61O8   NaN   \n",
       "34273      4.0     False   09 3, 2017  A2CF66KIQ3RKX3  B01GOZ61O8   NaN   \n",
       "34274      4.0     False   09 3, 2017  A1LKOIZXPQ9VG0  B01GOZ61O8   NaN   \n",
       "34275      1.0      True  08 25, 2017   AV2RWORXTFRJU  B01H353HUY   NaN   \n",
       "34276      5.0     False   07 8, 2017  A22S7D0LP8GRDH  B01H353HUY   NaN   \n",
       "34277      5.0      True   07 9, 2018   AAF5D1LTFGB7L  B01HGSJPMW   NaN   \n",
       "\n",
       "                reviewerName  \\\n",
       "34268                    JSM   \n",
       "34269                Jeddy 3   \n",
       "34270              Anna Hope   \n",
       "34271        Rachel McElhany   \n",
       "34272              Sandy Kay   \n",
       "34273           Vivian Deliz   \n",
       "34274               Elisa 20   \n",
       "34275            Gapeachmama   \n",
       "34276  Jacob and Kiki Hantla   \n",
       "34277          Libby Johnson   \n",
       "\n",
       "                                              reviewText  \\\n",
       "34268  Love it.  Just wish it came it bigger tube.  I...   \n",
       "34269  I really like the Tizo sunscreens, but this on...   \n",
       "34270  I used this on a recent trip across the countr...   \n",
       "34271  This product doesn't really say what it is. Th...   \n",
       "34272  I'm not sure whether it is the ceramicides or ...   \n",
       "34273  I like to use moisturizers and sunscreens that...   \n",
       "34274  I wouldn't be able to afford this if not asked...   \n",
       "34275                                        Did nothing   \n",
       "34276  I love the Oribe bright blonde radiance spray....   \n",
       "34277                 I love all of the Elemis products.   \n",
       "\n",
       "                                                 summary  unixReviewTime vote  \\\n",
       "34268                                         Great SPF!      1534809600  NaN   \n",
       "34269  Not sure what else it's doing, but it's defini...      1526860800  NaN   \n",
       "34270                                       Not Everyday      1512864000  NaN   \n",
       "34271                                  TIZO AM Replenish      1507593600  NaN   \n",
       "34272                       Hated how it felt on my face      1504915200  NaN   \n",
       "34273         Works great as a moisturizer and sunscreen      1504396800  NaN   \n",
       "34274  Nice skin care product and sunscreen if you do...      1504396800  NaN   \n",
       "34275                                           One Star      1503619200  NaN   \n",
       "34276                                     No more brass!      1499472000  NaN   \n",
       "34277                                         Five Stars      1531094400  NaN   \n",
       "\n",
       "      image  \n",
       "34268   NaN  \n",
       "34269   NaN  \n",
       "34270   NaN  \n",
       "34271   NaN  \n",
       "34272   NaN  \n",
       "34273   NaN  \n",
       "34274   NaN  \n",
       "34275   NaN  \n",
       "34276   NaN  \n",
       "34277   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89dd8c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34278\n"
     ]
    }
   ],
   "source": [
    "#Number of records\n",
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc3e4e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall\n",
       "1.0     1095\n",
       "2.0     1496\n",
       "3.0     3884\n",
       "4.0     7833\n",
       "5.0    19970\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No. of reviews/counts per rating\n",
    "df.groupby(by=\"overall\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ce4298c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText\n",
       "!!!! Yes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              2\n",
       "\" wonder how you ever lived without it\" you will be wondering a lot, it's big... if you see the picture and think too expensive (ok it is expensive), but it is also perfect and it will last because of the amount you will use, I've had mine for 4 days now and my lips are better i use it along with palmers lip balm ( check it out too) and you can't go wrong. Already ordered a limited edition set in red velvet that comes with the lip slip from Sara happ as well and I know I will be buying this forever. Recommend 100%                                                                                                                                                                                                                                                                                                                                                                                                               2\n",
       "\"A micelle (/masl/) or micella (/masl/) (plural micelles or micellae, respectively) is an aggregate of surfactant molecules dispersed in a liquid colloid.\"\\n\\nWell, alrighty then. This is the first toner/cleaner combination I've used and it seems to work very well . It leaves my skin feeling very clean although just a tad sticky for a while. It has a very subtle fragrance which smells floral to me.\\n\\nThe product is Soap-free. Alcohol-free. Colorant-free. pH-balanced. Allergy-tested. Non-comedogenic. Suitable for sensitive skin. Safe for contact lens wearers. Tested under dermatological and ophthalmological control .\\n\\nVichy is a L'Oreal brand, made in France. Don't ask me why the writing on the bottle  looks like Russian.\\n\\nThe ingredients are:\\n AQUA/WATER  HEXYLENE GLYCOL  GLYCERIN  POLOXAMER 184  DISODIUM COCOAMPHODIACETATE  DISODIUM EDTA  PANTHENOL  POLYAMINOPROPYL BIGUANIDE  PARFUM / FRAGRANCE    1\n",
       "\"Crown Me Already!\" (silver sparkle with various size glitter particles): This polish is amazing and got tons of comments, even from a guy that worked at Lowe's. Three coats are needed to get a solid diamond-like glitter from the nails, but after three days it started to chip off two of my nails, even with Seche Vite topcoat. The biggest problem I had was removal. This polish simply does not want to come off, even if you use a basecoat. It took nearly thirty minutes of intense scrubbing with pure acetone to finally remove the polish, and by that point my nails literally hurt. It is amazing but I will think twice about wearing this by itself again. This would NOT be good for a diamond-tip French manicure as some of the sparkles are quite large. It made the edges of my nails deadly-sharp and my boyfriend complained that I was scratching him. I even scratched my own face a few times.                         1\n",
       "\"Delicacy\" is closer to a light peach or pink-peach shade with a very muted shimmer. Very sheer with one coat and opaque in 4 coats but incredibly thick by that point.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               8\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ..\n",
       "wow, ordered yesterday got it today...love this product...sells for double the price in the salon I go to. So happy to have it at home                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
       "yes I like this product very much and will order again                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
       "yes, this sunscreen is expensive. But, for a high quality product that actually does what I need it to -- it is amazing! The sunscreen kept me protected and my face did not look greasy after applying.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1\n",
       "you have to use a lot if you have thick hair and for the price point it's not worth it. the peppermint essential oils in this are too concentrated and will burn your eyes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            2\n",
       "your lips so soft most of the time.thank you,sofia                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1\n",
       "Length: 24245, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=\"reviewText\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e4251e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489.144024514811"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate average length (mean) of reviewText\n",
    "df['reviewText'].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e649c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1[['reviewTime', 'year']]=df1['reviewTime'].str.split(',', 1, expand=True) \n",
    "#df1\n",
    "\n",
    "#df[['team', 'conference']] = df['team'].str.split(',', 1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e56df478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a representation of our vocabulary-list the words present in the reviewtext\n",
    "#if a word exists in reviewtext then 1 else 0\n",
    "#Create a function where we pass entire reviewtext and handed back a vector representation of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f0fcc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first step of preparing text for modeling is tokenizing documents. In this step, words are isolated by \n",
    "#transforming a text string with many words, like a sentence or a document, into a list of individual words.\n",
    "#When tokenizing:\n",
    "\n",
    "#'A machine will never replace a teacher.'\n",
    "\n",
    "#will be replaced with\n",
    "\n",
    "#['A', 'machine', 'will', 'never', 'replace', 'a', 'teacher.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "455ac2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a large language model and assign it to the spacy language variable 'nlp_lg'\n",
    "nlp_lg=spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20afc188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define example sentence\n",
    "text=\"I would like to have a dog and a cat in my home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b9ec795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feed example sentence to the language model under 'nlp_lg'\n",
    "#store the Spacy Doc object under the variable doc\n",
    "doc=nlp_lg(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8af96f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I would like to have a dog and a cat in my home"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show output\n",
    "#The model has learned by observing the word in its context of occurences\n",
    "doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63aee971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retreive 6th token in the Doc object\n",
    "doc[6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab9ece6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retreive 8th token in the Doc object\n",
    "doc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8214ffdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gives length of the vector\n",
    "#This doc object is represented by a 300 dimensional attribute\n",
    "doc.vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46930747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.049291,  0.20483 , -0.12808 , -0.086686, -0.11584 , -0.06313 ,\n",
       "       -0.11188 , -0.15493 , -0.30914 ,  3.1112  , -0.062078,  0.080439,\n",
       "        0.51842 ,  0.28753 , -0.33872 , -0.14584 , -0.23055 ,  0.73007 ,\n",
       "       -0.38358 , -0.074632,  0.15303 ,  0.076039,  0.032505, -0.040018,\n",
       "       -0.23066 ,  0.1503  , -0.24296 , -0.23203 ,  0.12932 , -0.1656  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retrieve the second Token in the doc and it's vector attributes \n",
    "#and retreive the first 30 dimensions of its vector representation\n",
    "doc[1].vector[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48369c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8016855120658875"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words that are similar should be close to each other in the word embeddings\n",
    "#similarity() method helps to take these words as input and calculate cosine similarity\n",
    "#between their vector representations stored under the vector representation for Doc pbjects\n",
    "#Calculate similarity between Dog and Cat which is .8 \n",
    "#They are similar as both tokens are both household pets\n",
    "\n",
    "dog=doc[6]\n",
    "cat=doc[9]\n",
    "dog.similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "702d72fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.similarity(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d75ca92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I, a dog, a cat, my home]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a list of noun phrases from the doc\n",
    "n_chunks=list(doc.noun_chunks)\n",
    "n_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e71e213c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.496260404586792"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare similarity of the vector representations for the first and last noun\n",
    "n_chunks[0].similarity(n_chunks[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f989f9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904877781867981"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare similarity of the vector representations for the first and last noun\n",
    "n_chunks[1].similarity(n_chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "214c7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=df[[\"overall\",\"reviewText\"]] \n",
    "df_final=df_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c53c54f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       overall                                         reviewText\n",
      "0          5.0  This handcream has a beautiful fragrance. It d...\n",
      "1          5.0  wonderful hand lotion, for seriously dry skin,...\n",
      "2          5.0  Best hand cream around.  Silky, thick, soaks i...\n",
      "3          5.0                                           Thanks!!\n",
      "4          5.0  Great hand lotion.  Soaks right in and leaves ...\n",
      "...        ...                                                ...\n",
      "34273      4.0  I like to use moisturizers and sunscreens that...\n",
      "34274      4.0  I wouldn't be able to afford this if not asked...\n",
      "34275      1.0                                        Did nothing\n",
      "34276      5.0  I love the Oribe bright blonde radiance spray....\n",
      "34277      5.0                 I love all of the Elemis products.\n",
      "\n",
      "[34265 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3df7d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull reviews into a panada dataframe\n",
    "#feed reviews to model stacy\n",
    "#get vector representation\n",
    "#use Sklearn to train and test the model\n",
    "#df_reviews=df_final[\"reviewText\"]  \n",
    "#df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2db421c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6094/3788551830.py:6: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df_final.vector=df_final.reviewText.apply(nlp_lg)\n"
     ]
    }
   ],
   "source": [
    "#Create a vector of words\n",
    "#Feed reviews column from Luxury Brand Pandas DF to the Stacy language model under 'nlp_lg'\n",
    "#Use apply function which takes reviews column Luxury Brand DF; iterates thru the rows in DF in an efficient way;\n",
    "#passing reviewText column\n",
    "\n",
    "df_final.vector=df_final.reviewText.apply(nlp_lg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "974b533e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        (This, handcream, has, a, beautiful, fragrance...\n",
       "1        (wonderful, hand, lotion, ,, for, seriously, d...\n",
       "2        (Best, hand, cream, around, .,  , Silky, ,, th...\n",
       "3                                           (Thanks, !, !)\n",
       "4        (Great, hand, lotion, .,  , Soaks, right, in, ...\n",
       "                               ...                        \n",
       "34273    (I, like, to, use, moisturizers, and, sunscree...\n",
       "34274    (I, would, n't, be, able, to, afford, this, if...\n",
       "34275                                       (Did, nothing)\n",
       "34276    (I, love, the, Oribe, bright, blonde, radiance...\n",
       "34277         (I, love, all, of, the, Elemis, products, .)\n",
       "Name: reviewText, Length: 34265, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "504efdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34265,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gives length of the vector\n",
    "#represented by a 300 dimensional attribute\n",
    "df_final.vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "685e783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This handcream has a beautiful fragrance. It doesnt stay on or protect your hands through washing.  This size is quite small."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #try to use df_final.vector column in train the model \n",
    "df_final.vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e88b4fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wonderful hand lotion, for seriously dry skin, stays on a long time, a little goes a long long way.. go easy.. wonderful scent.. maybe a bit strong at first, but dissipates after a while."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #try to use df_final.vector column in train the model \n",
    "df_final.vector[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd33848e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.39773318e-02,  1.60133287e-01, -1.69866487e-01, -1.19961366e-01,\n",
       "        3.71128134e-02, -8.83501619e-02,  2.16171713e-04, -2.29986593e-01,\n",
       "       -3.56430374e-02,  1.86375070e+00, -1.39553532e-01,  8.89517367e-02,\n",
       "       -3.03613804e-02, -8.78611356e-02, -9.06591788e-02, -8.26632604e-02,\n",
       "       -9.61264819e-02,  1.28135312e+00, -5.18032312e-02,  2.41618827e-02,\n",
       "       -5.21444231e-02,  2.68253181e-02, -6.32234442e-04,  9.43491831e-02,\n",
       "        6.51731193e-02,  5.83816580e-02, -7.97323436e-02, -5.04485629e-02,\n",
       "       -1.36352759e-02, -1.99832534e-03], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retrieve the first Token in the doc and it's vector attributes \n",
    "#and retreive the first 30 dimensions of its vector representation\n",
    "df_final.vector[0].vector[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31d922cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9326830525839549"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words that are similar should be close to each other in the embeddings\n",
    "#similarity() method helps to take these words as input and calculate cosine similarity\n",
    "#between their vector representations stored under the vector representation for Doc pbjects\n",
    "#Calculate similarity between 2 reviews\n",
    "#They are similar as both are about Handcream/lotion\n",
    "\n",
    "r1=df_final.vector[0]\n",
    "r2=df_final.vector[1]\n",
    "r1.similarity(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cb1942a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create set which only has keys\n",
    "#vocab_set=set() \n",
    "#for review in df_final.vector:  \n",
    "#    vocab_set.update(set(review.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2d8e831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "fb215535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "499cd1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector of the words\n",
    "#make a dict of keys\n",
    "#def create_vector_of_words(vocab,review): \n",
    "#    vector=dict.fromkeys(vocab,0)\n",
    "#    for word in review:  \n",
    "#       vector[word] = vector[word]+1\n",
    "        \n",
    "         \n",
    "#    return vector\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "039514c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to create a dict from a set of words\n",
    "#want to find out if word exists\n",
    "#v1=create_vector_of_words(vocab_set,df_reviews[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "03230f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words representation on our data\n",
    "#v1['handcream']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "568f2eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "833e726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict.fromkeys(vocab_set,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a8782d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sklearn library ; uses C ; Initialize a vectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a67b9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create numpy array which uses this list of reviews\n",
    "#reviews=np.array(df_reviews)\n",
    "reviews=np.array(df_final.vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8f4703bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([This handcream has a beautiful fragrance. It doesnt stay on or protect your hands through washing.  This size is quite small.,\n",
       "       wonderful hand lotion, for seriously dry skin, stays on a long time, a little goes a long long way.. go easy.. wonderful scent.. maybe a bit strong at first, but dissipates after a while.,\n",
       "       Best hand cream around.  Silky, thick, soaks in all the way leaving hands super soft.,\n",
       "       ..., Did nothing,\n",
       "       I love the Oribe bright blonde radiance spray. I've been using it twice a week for about 8 weeks and I didn't have brassiness between colors. I know some complained about dryness, but I didn't have that experience. I highly recommend this for use between colors.,\n",
       "       I love all of the Elemis products.], dtype=object)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "2a29a766",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2334/323132463.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#pass a list of reviews and will create a BOW rep off our data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#pass set of vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbag_of_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \"\"\"\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "#pass a list of reviews and will create a BOW rep off our data\n",
    "#pass set of vectors\n",
    "bag_of_words=vectorizer.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6cd60afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse matrix-mostly 0 \n",
    "#bag_of_words=bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "dc75cd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5.0\n",
       "1        5.0\n",
       "2        5.0\n",
       "3        5.0\n",
       "4        5.0\n",
       "        ... \n",
       "34273    4.0\n",
       "34274    4.0\n",
       "34275    1.0\n",
       "34276    5.0\n",
       "34277    5.0\n",
       "Name: overall, Length: 34265, dtype: float64"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#panada series of the reviews\n",
    "df_ratings=df_final[\"overall\"]  \n",
    "df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c01ef868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create numpy array which uses this list of ratings\n",
    "ratings=np.array(df_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "229ab75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., ..., 1., 5., 5.])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6688f766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34265"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a01c76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test our model ;x inputs y outcome\n",
    "#Split arrays into random train and test subsets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_final.vector, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1a299d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 5., 5., ..., 5., 3., 5.])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e42e39db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 4., ..., 4., 5., 5.])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "36ae6abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25698, 25698)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8c1634dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8567, 8567)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "dc9f9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of a model ; Initialising the model ; logisticregression (watch video) ; use tgidf\n",
    "lr = LogisticRegression(C=10.0, random_state=1, solver='lbfgs', multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7b0d069b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'spacy.tokens.doc.Doc'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2334/2833971614.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Learning/Training of model ; reviews & scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1509\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    855\u001b[0m               dtype='datetime64[ns]')\n\u001b[1;32m    856\u001b[0m         \"\"\"\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#Learning/Training of model ; reviews & scores\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "595c5fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0d0dc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., ..., 4., 2., 5.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction array\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "568c2048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 4., ..., 5., 2., 5.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#actual data \n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc5928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the prediction and then compare it with actual ratings  \n",
    "\n",
    "#71% accuracy of the prediction; \n",
    "#The prediction percent is better score that 58% cause the model has actually learned "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90772a0e",
   "metadata": {},
   "source": [
    "metrics.accuracy_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42f6a3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    19963\n",
       "4.0     7831\n",
       "3.0     3880\n",
       "2.0     1496\n",
       "1.0     1095\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2ffecde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34265"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df3d5dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5826061578870567"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19963/34265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d51431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
