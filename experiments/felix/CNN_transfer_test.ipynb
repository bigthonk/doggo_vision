{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6cef85b",
   "metadata": {},
   "source": [
    "# Transfer Learning CNN Test\n",
    "\n",
    "Creation date: March 2022\n",
    "\n",
    "Edit date: March 31, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcf45c7",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Synthetic data\n",
    "* Improve modularity of code\n",
    "* Create df to log experiments\n",
    "* Test other models to resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80f3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import time\n",
    "\n",
    "# Torch libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "### From Dan:\n",
    "\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler, random_split\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c31a80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/git/doggo_vision/experiments/felix\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd59078",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('..')\n",
    "os.chdir('dogs/Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49eeb92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## REPLACE WITH YOUR NAME TO LOCATE FILES IN YOUR REPO ########################\n",
    "YOUR_NAME=\"felix\"\n",
    "\n",
    "# Why is model worse than dan's\n",
    "# pay special attention to the dataset. data portion.\n",
    "# Training mechanism compared to what I'm doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93537160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create labels dataframe and save to csv\n",
    "# labels = ['Chihuahua']\n",
    "# image_path = []\n",
    "# label_num = []\n",
    "\n",
    "# label_count = 0\n",
    "# for root, dirs, files in os.walk(\".\"):\n",
    "#     for name in files:\n",
    "#         labels.append(root.split(\"-\",1)[1])\n",
    "#         image_path.append(os.path.join(root, name))\n",
    "        \n",
    "#         if labels[-1] != labels[-2]:\n",
    "#             label_count += 1\n",
    "        \n",
    "#         label_num.append(label_count)\n",
    "        \n",
    "\n",
    "# df = pd.DataFrame({'labels':labels[1:],'image_path':image_path, 'label_num':label_num}) \n",
    "\n",
    "# # Create label dict for later use\n",
    "# breeds = pd.Series(df.labels.values,index=df.label_num).to_dict()\n",
    "\n",
    "# # saving the dataframe \n",
    "# df.to_csv(\"../../experiments/\"+YOUR_NAME+\"/annotations.csv\") \n",
    "# display(df.head())\n",
    "# display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4300e72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  400 \n",
      "Label:  Maltese_dog \n",
      "Image directory:  ./n02085936-Maltese_dog/n02085936_426.jpg \n",
      "Label number:  2\n",
      "\n",
      "Total number of samples:  20580 \n",
      "Dog breeds/ unique labels:  120\n",
      "\n",
      "Number images per breed \n",
      "Max:  252 \n",
      "Min: 148\n"
     ]
    }
   ],
   "source": [
    "# Test labels\n",
    "doggo_labels = pd.read_csv(\"../../experiments/\"+YOUR_NAME+\"/annotations.csv\")\n",
    "index = 400\n",
    "\n",
    "print(\"Index: \", doggo_labels.iloc[index, 0], \"\\nLabel: \", doggo_labels.iloc[index, 1], \"\\nImage directory: \", doggo_labels.iloc[index, 2], \"\\nLabel number: \", doggo_labels.iloc[index, 3])\n",
    "print(\"\\nTotal number of samples: \", doggo_labels.shape[0], \"\\nDog breeds/ unique labels: \", len(pd.unique(doggo_labels['labels'])))\n",
    "print(\"\\nNumber images per breed \\nMax: \", max(doggo_labels['labels'].value_counts()), \"\\nMin:\", min(doggo_labels['labels'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43883c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, validate and test with proportional classes\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "label_num = np.array(doggo_labels.iloc[:, 3])\n",
    "\n",
    "# labels\n",
    "dataY = label_num\n",
    "\n",
    "# features\n",
    "dataX_dummy = range(len(label_num)) \n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "index_train, index_test, y_train, y_test = train_test_split(dataX_dummy, dataY, test_size=1 - train_ratio, stratify=dataY)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "index_val, index_test, y_val, y_test = train_test_split(index_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35336c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check indices work\n",
    "# img_annotations = pd.read_csv(\"../../experiments/\"+YOUR_NAME+\"/annotations.csv\").iloc[index_train]\n",
    "# display(img_annotations.head())\n",
    "# print(img_annotations.iloc[0,2])\n",
    "# print(img_annotations.iloc[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daa18be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "n_pixels = 300\n",
    "n_degrees = 15\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=n_pixels+15, scale=(0.95, 1.0)),\n",
    "    transforms.RandomRotation(degrees=n_degrees),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.CenterCrop(size=n_pixels),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*imagenet_stats) \n",
    "]) #these values come from ImageNet Dataset mean and std (resnet50 trained on ImageNet)    \n",
    "# transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "\n",
    "\n",
    "# Other transforms?\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(size=n_pixels),\n",
    "    transforms.CenterCrop(size=n_pixels),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*imagenet_stats) \n",
    "#     transforms.HorizontalFlip(),\n",
    "#     transforms.RandomRotation(degrees = (0,180)),\n",
    "#     transforms.RandomVerticalFlip()\n",
    "]) #these values come from ImageNet Dataset mean and std (resnet50 trained on ImageNet)\n",
    "\n",
    "# Other transforms?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90742d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1 - just resize\n",
    "class DoggoDataset(Dataset):\n",
    "    def __init__(self, indices, transform=None):\n",
    "        self.img_annotations = pd.read_csv(\"../../experiments/\"+YOUR_NAME+\"/annotations.csv\").iloc[indices]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_annotations.iloc[idx, 2]\n",
    "        image = Image.open(img_path)\n",
    "        image = image.convert('RGB')\n",
    "        label = self.img_annotations.iloc[idx, 3]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24dcc5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DoggoDataset(index_train, transform_train)\n",
    "val_set = DoggoDataset(index_val, transform_val)\n",
    "test_set = DoggoDataset(index_test)\n",
    "\n",
    "num_workers=4\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ff0d6c",
   "metadata": {},
   "source": [
    "## Custom functions\n",
    "\n",
    "Using functions created by Chinmay and Nora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78e1228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred, true):\n",
    "    # Calculating accuracy by comparing predictions with true labels\n",
    "    acc = [1 if pred[i] == true[i] else 0 for i in range(len(pred))]\n",
    "    # Compute accuracy\n",
    "    acc = np.sum(acc) / len(pred)\n",
    "\n",
    "    return acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8303a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_dataloader):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    for images, labels in train_dataloader:\n",
    "        \n",
    "        # ResNet is trained on images with only 3 channels\n",
    "        if(images.shape[1] == 3):\n",
    "            \n",
    "            # Load images and labels to device - in our case GPU!\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.to(torch.long)\n",
    "        \n",
    "            # Reseting Gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            with torch.set_grad_enabled(True):\n",
    "                preds = model(images)\n",
    "                _, max_pred = torch.max(preds, 1)\n",
    "\n",
    "            # Calculating Loss\n",
    "            _loss = criterion(preds, labels)\n",
    "            loss = _loss.item()\n",
    "            epoch_loss.append(loss)\n",
    "\n",
    "            # Calculating Accuracy\n",
    "            acc = get_accuracy(max_pred, labels)\n",
    "            epoch_acc.append(acc)\n",
    "\n",
    "            # Backward\n",
    "            _loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    lr_scheduler.step()\n",
    "    # Overall Epoch Results\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Acc and Loss\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    epoch_acc = np.mean(epoch_acc)\n",
    "    \n",
    "    # Log the results\n",
    "    train_logs[\"loss\"].append(epoch_loss)\n",
    "    train_logs[\"accuracy\"].append(epoch_acc)\n",
    "    train_logs[\"time\"].append(total_time)\n",
    "        \n",
    "    return epoch_loss, epoch_acc, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78c5b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_one_epoch(val_dataloader, best_val_acc):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    start_time = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    for images, labels in val_dataloader:\n",
    "        \n",
    "        # ResNet is trained on images with only 3 channels\n",
    "        if(images.shape[1] == 3):\n",
    "        \n",
    "            # Load images and labels to device - again GPU!\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "#             labels = labels.reshape((1,labels.shape[0])) # [N, 1] - to match with preds shape\n",
    "            labels = labels.to(torch.long)\n",
    "\n",
    "            # Forward\n",
    "            preds = model(images)\n",
    "            _, max_pred = torch.max(preds, 1)\n",
    "            \n",
    "            # Calculating Loss\n",
    "            _loss = criterion(preds, labels)\n",
    "            loss = _loss.item()\n",
    "            epoch_loss.append(loss)\n",
    "\n",
    "            # Calculating Accuracy\n",
    "            acc = get_accuracy(max_pred, labels)\n",
    "            epoch_acc.append(acc)\n",
    "    \n",
    "    # Overall Epoch Results\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Acc and Loss\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    epoch_acc = np.mean(epoch_acc)\n",
    "    \n",
    "    # Log the results\n",
    "    val_logs[\"loss\"].append(epoch_loss)\n",
    "    val_logs[\"accuracy\"].append(epoch_acc)\n",
    "    val_logs[\"time\"].append(total_time)\n",
    "    \n",
    "    # Save the best model\n",
    "    if epoch_acc > best_val_acc:\n",
    "        best_val_acc = epoch_acc\n",
    "        torch.save(model.state_dict(),\"resnet50_best.pth\")\n",
    "        \n",
    "    return epoch_loss, epoch_acc, total_time, best_val_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b1d429",
   "metadata": {},
   "source": [
    "## ResNet50\n",
    "\n",
    "Let's goooooo - Chinmay 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a399cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5c611c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model):\n",
    "    model.aux_logits=False\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    n_classes = 120\n",
    "    n_inputs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(n_inputs, n_classes),\n",
    "        nn.LogSoftmax(dim=1))\n",
    "    model.cuda()\n",
    "#     model.class_to_idx = all_data.class_to_idx\n",
    "#     model.idx_to_class = {\n",
    "#         idx: class_\n",
    "#         for class_, idx in model.class_to_idx.items()\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eb5bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 120\n",
    "\n",
    "model = resnet50(pretrained = True)\n",
    "build_model(model)\n",
    "\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# num_ftrs = model.fc.in_features\n",
    "\n",
    "# # model.fc = nn.Linear(num_ftrs, 120)\n",
    "\n",
    "# model.fc = nn.Sequential(\n",
    "# nn.Linear(num_ftrs, 1024),\n",
    "# nn.ReLU(),\n",
    "# nn.Dropout(0.4),\n",
    "# nn.Linear(1024, n_classes),\n",
    "# nn.LogSoftmax(dim=1))\n",
    "\n",
    "# repeat experiment and change head... \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5db414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a7e5dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer=optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) #step_size = 5, gamma = 0.5)\n",
    "\n",
    "# Loss Function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Logs\n",
    "train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
    "val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
    "\n",
    "# Loading model to device\n",
    "model.to(device)\n",
    "\n",
    "# No of epochs \n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f78683bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb0e5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc02bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training\n",
      "Epoch 1\n",
      "Loss : 4.5534\n",
      "Acc : 0.1183\n",
      "Time : 343.6766\n",
      "\n",
      "Validating\n",
      "Epoch 1\n",
      "Loss : 4.2062\n",
      "Acc : 0.2719\n",
      "Time : 70.0354\n",
      "\n",
      "Training\n",
      "Epoch 2\n",
      "Loss : 3.9606\n",
      "Acc : 0.3931\n",
      "Time : 285.3153\n",
      "\n",
      "Validating\n",
      "Epoch 2\n",
      "Loss : 3.6224\n",
      "Acc : 0.5279\n",
      "Time : 45.3476\n",
      "\n",
      "Training\n",
      "Epoch 3\n",
      "Loss : 3.4413\n",
      "Acc : 0.5737\n",
      "Time : 349.4309\n",
      "\n",
      "Validating\n",
      "Epoch 3\n",
      "Loss : 3.1266\n",
      "Acc : 0.6434\n",
      "Time : 69.0597\n",
      "\n",
      "Training\n",
      "Epoch 4\n",
      "Loss : 2.9954\n",
      "Acc : 0.6655\n",
      "Time : 349.1805\n",
      "\n",
      "Validating\n",
      "Epoch 4\n",
      "Loss : 2.7155\n",
      "Acc : 0.7106\n",
      "Time : 71.1366\n",
      "\n",
      "Training\n",
      "Epoch 5\n",
      "Loss : 2.6167\n",
      "Acc : 0.7281\n",
      "Time : 348.0804\n",
      "\n",
      "Validating\n",
      "Epoch 5\n",
      "Loss : 2.3551\n",
      "Acc : 0.7625\n",
      "Time : 68.1187\n",
      "\n",
      "Training\n",
      "Epoch 6\n",
      "Loss : 2.3059\n",
      "Acc : 0.763\n",
      "Time : 346.4564\n",
      "\n",
      "Validating\n",
      "Epoch 6\n",
      "Loss : 2.0721\n",
      "Acc : 0.7809\n",
      "Time : 67.9894\n",
      "\n",
      "Training\n",
      "Epoch 7\n",
      "Loss : 2.0545\n",
      "Acc : 0.7903\n",
      "Time : 346.5604\n",
      "\n",
      "Validating\n",
      "Epoch 7\n",
      "Loss : 1.847\n",
      "Acc : 0.8069\n",
      "Time : 68.2421\n",
      "\n",
      "Training\n",
      "Epoch 8\n",
      "Loss : 1.928\n",
      "Acc : 0.8033\n",
      "Time : 347.7819\n",
      "\n",
      "Validating\n",
      "Epoch 8\n",
      "Loss : 1.8263\n",
      "Acc : 0.7987\n",
      "Time : 71.3052\n",
      "\n",
      "Training\n",
      "Epoch 9\n",
      "Loss : 1.906\n",
      "Acc : 0.8065\n",
      "Time : 351.8721\n",
      "\n",
      "Validating\n",
      "Epoch 9\n",
      "Loss : 1.8205\n",
      "Acc : 0.8031\n",
      "Time : 67.2805\n",
      "\n",
      "Training\n",
      "Epoch 10\n",
      "Loss : 1.8888\n",
      "Acc : 0.8104\n",
      "Time : 346.273\n",
      "\n",
      "Validating\n",
      "Epoch 10\n",
      "Loss : 1.7949\n",
      "Acc : 0.8048\n",
      "Time : 68.3747\n",
      "\n",
      "Training\n",
      "Epoch 11\n",
      "Loss : 1.8649\n",
      "Acc : 0.8124\n",
      "Time : 347.9071\n",
      "\n",
      "Validating\n",
      "Epoch 11\n",
      "Loss : 1.7685\n",
      "Acc : 0.813\n",
      "Time : 68.6581\n",
      "\n",
      "Training\n",
      "Epoch 12\n",
      "Loss : 1.8489\n",
      "Acc : 0.8137\n",
      "Time : 349.112\n",
      "\n",
      "Validating\n",
      "Epoch 12\n",
      "Loss : 1.7535\n",
      "Acc : 0.8084\n",
      "Time : 69.4735\n",
      "\n",
      "Training\n",
      "Epoch 13\n",
      "Loss : 1.8288\n",
      "Acc : 0.8154\n",
      "Time : 344.6979\n",
      "\n",
      "Validating\n",
      "Epoch 13\n",
      "Loss : 1.7302\n",
      "Acc : 0.8133\n",
      "Time : 68.7818\n",
      "\n",
      "Training\n",
      "Epoch 14\n",
      "Loss : 1.8104\n",
      "Acc : 0.8149\n",
      "Time : 347.6718\n",
      "\n",
      "Validating\n",
      "Epoch 14\n",
      "Loss : 1.7232\n",
      "Acc : 0.8134\n",
      "Time : 69.7875\n",
      "\n",
      "Training\n",
      "Epoch 15\n",
      "Loss : 1.7983\n",
      "Acc : 0.8193\n",
      "Time : 349.5026\n",
      "\n",
      "Validating\n",
      "Epoch 15\n",
      "Loss : 1.7182\n",
      "Acc : 0.8123\n",
      "Time : 67.2125\n",
      "\n",
      "Training\n",
      "Epoch 16\n",
      "Loss : 1.8004\n",
      "Acc : 0.8158\n",
      "Time : 350.2731\n",
      "\n",
      "Validating\n",
      "Epoch 16\n",
      "Loss : 1.7211\n",
      "Acc : 0.8049\n",
      "Time : 69.8953\n",
      "\n",
      "Training\n",
      "Epoch 17\n",
      "Loss : 1.7972\n",
      "Acc : 0.8191\n",
      "Time : 348.0211\n",
      "\n",
      "Validating\n",
      "Epoch 17\n",
      "Loss : 1.721\n",
      "Acc : 0.8153\n",
      "Time : 70.9\n",
      "\n",
      "Training\n",
      "Epoch 18\n",
      "Loss : 1.7996\n",
      "Acc : 0.8175\n",
      "Time : 350.0314\n",
      "\n",
      "Validating\n",
      "Epoch 18\n",
      "Loss : 1.709\n",
      "Acc : 0.8159\n",
      "Time : 68.8321\n",
      "\n",
      "Training\n",
      "Epoch 19\n",
      "Loss : 1.7935\n",
      "Acc : 0.8206\n",
      "Time : 302.0998\n",
      "\n",
      "Validating\n",
      "Epoch 19\n",
      "Loss : 1.7119\n",
      "Acc : 0.8096\n",
      "Time : 57.8958\n",
      "\n",
      "Training\n",
      "Epoch 20\n",
      "Loss : 1.7953\n",
      "Acc : 0.818\n",
      "Time : 286.3722\n",
      "\n",
      "Validating\n",
      "Epoch 20\n",
      "Loss : 1.7047\n",
      "Acc : 0.8126\n",
      "Time : 56.7863\n",
      "\n",
      "Training\n",
      "Epoch 21\n",
      "Loss : 1.7917\n",
      "Acc : 0.8173\n",
      "Time : 281.559\n",
      "\n",
      "Validating\n",
      "Epoch 21\n",
      "Loss : 1.7136\n",
      "Acc : 0.8136\n",
      "Time : 56.7387\n",
      "\n",
      "Training\n",
      "Epoch 22\n",
      "Loss : 1.7896\n",
      "Acc : 0.8174\n",
      "Time : 281.9317\n",
      "\n",
      "Validating\n",
      "Epoch 22\n",
      "Loss : 1.7032\n",
      "Acc : 0.8081\n",
      "Time : 57.3939\n",
      "\n",
      "Training\n",
      "Epoch 23\n",
      "Loss : 1.7933\n",
      "Acc : 0.8179\n",
      "Time : 284.0254\n",
      "\n",
      "Validating\n",
      "Epoch 23\n",
      "Loss : 1.7115\n",
      "Acc : 0.8096\n",
      "Time : 56.9855\n",
      "\n",
      "Training\n",
      "Epoch 24\n",
      "Loss : 1.7904\n",
      "Acc : 0.82\n",
      "Time : 281.6599\n",
      "\n",
      "Validating\n",
      "Epoch 24\n",
      "Loss : 1.6986\n",
      "Acc : 0.8126\n",
      "Time : 55.6422\n",
      "\n",
      "Training\n",
      "Epoch 25\n",
      "Loss : 1.7929\n",
      "Acc : 0.8162\n",
      "Time : 283.7217\n",
      "\n",
      "Validating\n",
      "Epoch 25\n",
      "Loss : 1.7061\n",
      "Acc : 0.8079\n",
      "Time : 56.8655\n",
      "\n",
      "Training\n",
      "Epoch 26\n",
      "Loss : 1.7883\n",
      "Acc : 0.8185\n",
      "Time : 284.0743\n",
      "\n",
      "Validating\n",
      "Epoch 26\n",
      "Loss : 1.7088\n",
      "Acc : 0.8109\n",
      "Time : 57.2475\n",
      "\n",
      "Training\n",
      "Epoch 27\n",
      "Loss : 1.7884\n",
      "Acc : 0.8194\n",
      "Time : 288.3927\n",
      "\n",
      "Validating\n",
      "Epoch 27\n",
      "Loss : 1.6941\n",
      "Acc : 0.8175\n",
      "Time : 57.3725\n",
      "\n",
      "Training\n",
      "Epoch 28\n",
      "Loss : 1.7843\n",
      "Acc : 0.8191\n",
      "Time : 287.7361\n",
      "\n",
      "Validating\n",
      "Epoch 28\n",
      "Loss : 1.7086\n",
      "Acc : 0.8129\n",
      "Time : 57.2517\n",
      "\n",
      "Training\n",
      "Epoch 29\n",
      "Loss : 1.7862\n",
      "Acc : 0.8187\n",
      "Time : 284.1126\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0 # this will be computed in the validation step\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Training\n",
    "    loss, acc, _time = train_one_epoch(train_dataloader)\n",
    "    \n",
    "    print(\"\\nTraining\")\n",
    "    print(\"Epoch {}\".format(epoch+1))\n",
    "    print(\"Loss : {}\".format(round(loss, 4)))\n",
    "    print(\"Acc : {}\".format(round(acc, 4)))\n",
    "    print(\"Time : {}\".format(round(_time, 4)))\n",
    "    \n",
    "    # Validation\n",
    "    loss, acc, _time, best_val_acc = val_one_epoch(val_dataloader, best_val_acc)\n",
    "    \n",
    "    print(\"\\nValidating\")\n",
    "    print(\"Epoch {}\".format(epoch+1))\n",
    "    print(\"Loss : {}\".format(round(loss, 4)))\n",
    "    print(\"Acc : {}\".format(round(acc, 4)))\n",
    "    print(\"Time : {}\".format(round(_time, 4)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa652216",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2036973a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(transform)\n",
    "# best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a783e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df = pd.read_csv(\"../../experiments/\"+YOUR_NAME+\"/experiments_df.csv\")\n",
    "experiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd54c02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save experiment settings and result. \n",
    "# criterion\n",
    "experiment_df = pd.read_csv(\"../../experiments/\"+YOUR_NAME+\"/experiments_df.csv\")\n",
    "experiment_df.loc[len(experiment_df.index)] = [epochs, best_val_acc, learning_rate, batch_size, momentum, transform_train, model]\n",
    "#                               \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_df.head()\n",
    "# experiment_df.loc[len(experiment_df.index)] = [epochs, best_val_acc, learning_rate, batch_size, momentum, transform_train, model]\n",
    "experiment_df.head(20)\n",
    "# [epochs, best_val_acc, learning_rate, batch_size, momentum, transform_train, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df.to_csv(\"../../experiments/\"+YOUR_NAME+\"/experiments_df.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16afe0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(),f\"../../experiments/{YOUR_NAME}/resnet50_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e7db19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8999c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0679c265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca57e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e3a63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51417e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e2067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be34c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af32871b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3e4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181cda3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f26952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p37)",
   "language": "python",
   "name": "conda_pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
