{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88baf26a",
   "metadata": {},
   "source": [
    "# Build a model 2.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7230af8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ff5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import spacy\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "### Word2Vec Model\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e57ff2",
   "metadata": {},
   "source": [
    "## Read functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a09756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825c5db",
   "metadata": {},
   "source": [
    "## Clean and preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4f17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd2da274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(df):\n",
    "    \"Extract relevant text from DataFrame using a regex\"\n",
    "    # Regex pattern for only alphanumeric, hyphenated text with 3 or more chars\n",
    "    pattern = re.compile(r\"[A-Za-z0-9\\-]{3,50}\")\n",
    "    df['clean'] = df['reviewText'].str.findall(pattern).str.join(' ')\n",
    "    return df\n",
    "\n",
    "def lemmatize_pipe(doc):\n",
    "    lemma_list = [str(tok.lemma_).lower() for tok in doc\n",
    "                  if tok.is_alpha and tok.text.lower() not in stopwords] \n",
    "    return lemma_list\n",
    "\n",
    "def preprocess_pipe(texts):\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=20):\n",
    "        preproc_pipe.append(lemmatize_pipe(doc))\n",
    "    return preproc_pipe\n",
    "\n",
    "def chunker(iterable, total_length, chunksize):\n",
    "    return (iterable[pos: pos + chunksize] for pos in range(0, total_length, chunksize))\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    \"Flatten a list of lists to a combined list\"\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "def process_chunk(texts):\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=20):\n",
    "        preproc_pipe.append(lemmatize_pipe(doc))\n",
    "    return preproc_pipe\n",
    "\n",
    "def preprocess_parallel(texts, chunksize=100):\n",
    "    executor = Parallel(n_jobs=7, backend='multiprocessing', prefer=\"processes\")\n",
    "    do = delayed(process_chunk)\n",
    "    tasks = (do(chunk) for chunk in chunker(texts, len(df_clean), chunksize=chunksize))\n",
    "    result = executor(tasks)\n",
    "    return flatten(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278afc12",
   "metadata": {},
   "source": [
    "## Corpus and one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d25ebd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[adverse, comment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[gift, college, student]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[like, strong, tea, little, strong]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                 text\n",
       "0      5.0                   [adverse, comment]\n",
       "1      5.0             [gift, college, student]\n",
       "2      5.0  [like, strong, tea, little, strong]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_limit = 100000\n",
    "set_chunksize = 500\n",
    "\n",
    "stopwords = text.ENGLISH_STOP_WORDS\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "raw_df = getDF('../../../../data/Grocery_and_Gourmet_Food_5.json.gz')\n",
    "raw_df = raw_df.dropna(subset = [\"reviewText\"])\n",
    "\n",
    "df_limit = raw_df.head(n_limit)\n",
    "df_clean = cleaner(df_limit)\n",
    "\n",
    "df_clean['text'] = preprocess_parallel(df_clean['clean'], chunksize=set_chunksize)\n",
    "\n",
    "df_clean = df_clean[[\"overall\", \"text\"]]\n",
    "\n",
    "df_clean.head(3)\n",
    "# loc[row_indexer,col_indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = getDF('../../../../data/Grocery_and_Gourmet_Food_5.json.gz')\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nora's code:\n",
    "# df=df[[\"reviewText\"]]\n",
    "\n",
    "# df[\"split_reviewText\"]=df[\"reviewText\"].str.lower()\n",
    "# df=df[[\"split_reviewText\"]]\n",
    "\n",
    "# rem=string.punctuation\n",
    "# pattern = r\"[{}]\".format(rem)\n",
    "# df[\"split_reviewText\"]=df[\"split_reviewText\"].str.replace(pattern, '')\n",
    "\n",
    "# df[\"split_reviewText\"]=df.split_reviewText.str.split(\" \")\n",
    "\n",
    "# # Nora's code:\n",
    "# df_clean = df[[\"reviewText\"]]\n",
    "# df_clean = cleaner(df_clean)\n",
    "\n",
    "# df_clean[\"split_reviewText\"]=df_clean[\"reviewText\"].str.lower()\n",
    "# df_clean = df_clean[[\"split_reviewText\"]]\n",
    "\n",
    "# rem = string.punctuation\n",
    "# pattern = r\"[{}]\".format(rem)\n",
    "# df_clean[\"split_reviewText\"]=df_clean[\"split_reviewText\"].str.replace(pattern, '')\n",
    "\n",
    "# df_clean[\"split_reviewText\"]=df_clean.split_reviewText.str.split(\" \")\n",
    "# df_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ccdc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean['split_reviewText']\n",
    "# df_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3d8193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of list format of the custom corpus for gensim modeling \n",
    "# sent = [row for row in df_clean['split_reviewText']]\n",
    "sent = list(df_clean['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aabf368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['adverse', 'comment'],\n",
       " ['gift', 'college', 'student'],\n",
       " ['like', 'strong', 'tea', 'little', 'strong'],\n",
       " ['love',\n",
       "  'tea',\n",
       "  'flavor',\n",
       "  'way',\n",
       "  'well',\n",
       "  'regular',\n",
       "  'lipton',\n",
       "  'black',\n",
       "  'tea',\n",
       "  'definetly',\n",
       "  'worth',\n",
       "  'money'],\n",
       " ['search',\n",
       "  'browse',\n",
       "  'amazon',\n",
       "  'tea',\n",
       "  'lipton',\n",
       "  'sell',\n",
       "  'grocery',\n",
       "  'store',\n",
       "  'shelf',\n",
       "  'stuff',\n",
       "  'purchase',\n",
       "  'just',\n",
       "  'awful',\n",
       "  'near',\n",
       "  'good',\n",
       "  'remember']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46607c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sent, min_count=1,vector_size= 50,workers=3, window =5, sg = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04b7079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.56914383  0.44229633 -0.08588842  0.00905657 -1.0971054   0.26600435\n",
      "  0.6358879   0.11039567 -0.4812935  -0.2776121  -0.10902502 -0.6501509\n",
      " -0.08723716  0.68138844 -0.5863477  -0.16933496  0.21681567  0.32548955\n",
      " -0.12870976 -0.5939464  -0.28272468  0.44033     0.6807964  -0.75070465\n",
      "  0.27004883 -0.32829216 -0.5868924   0.07159974  0.11104973  0.22327894\n",
      " -0.09788269 -0.01286444 -0.32635158 -0.36721665 -0.697452    1.0271446\n",
      " -0.0522331  -0.11789049  0.2700275  -0.49165687 -0.18336883  0.54660004\n",
      " -0.32295758  0.27195424  0.760365    0.14604013 -0.29991692 -0.40308306\n",
      "  0.87348497  0.36599055]\n",
      "[('cookies', 0.8529347777366638), ('shortbread', 0.8285030722618103), ('brownie', 0.8106359243392944), ('fudge', 0.7925254702568054), ('biscotti', 0.7817010283470154), ('pecan', 0.7776121497154236), ('murray', 0.774254322052002), ('walker', 0.7648388147354126), ('nutella', 0.7632539868354797), ('choc', 0.7627608180046082)]\n",
      "[('cupcake', 0.8975176811218262), ('icing', 0.8860847353935242), ('frosting', 0.860694408416748), ('buttercream', 0.8543232083320618), ('frost', 0.8488162159919739), ('velvet', 0.8376407027244568), ('decoration', 0.8293403387069702), ('decorate', 0.8107447028160095), ('sparkly', 0.8078892827033997), ('pastry', 0.7944011688232422)]\n",
      "[('choc', 0.835982084274292), ('hershey', 0.8207488059997559), ('fudge', 0.8019393086433411), ('cocoa', 0.7903843522071838), ('cadbury', 0.7696358561515808), ('ganache', 0.7679648995399475), ('bittersweet', 0.7654815912246704), ('chocoholic', 0.7651674151420593), ('nestle', 0.7643521428108215), ('bar', 0.7603658437728882)]\n"
     ]
    }
   ],
   "source": [
    "# model(\"tea\")\n",
    "vector = model.wv['cookie']\n",
    "print(vector)\n",
    "sims = model.wv.most_similar('cookie', topn=10)\n",
    "print(sims)\n",
    "sims = model.wv.most_similar('cake', topn=10)\n",
    "print(sims)\n",
    "sims = model.wv.most_similar('chocolate', topn=10)\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2f845c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cupcake', 0.8975176811218262),\n",
       " ('icing', 0.8860847353935242),\n",
       " ('frosting', 0.860694408416748),\n",
       " ('buttercream', 0.8543232083320618),\n",
       " ('frost', 0.8488162159919739)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('cake')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd2aef7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cookies', 0.8529347777366638),\n",
       " ('shortbread', 0.8285030722618103),\n",
       " ('brownie', 0.8106359243392944),\n",
       " ('fudge', 0.7925254702568054),\n",
       " ('biscotti', 0.7817010283470154)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('cookie')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "973bae23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74429965"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"cookie\", \"biscuit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ef49667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7183425"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"cookie\", \"cake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e907eef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64192384"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"biscuit\", \"bread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3753e829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bread', 0.8836270570755005),\n",
       " ('meatloaf', 0.8595864176750183),\n",
       " ('meat', 0.8476506471633911),\n",
       " ('pizza', 0.831365168094635),\n",
       " ('loafs', 0.8200547099113464),\n",
       " ('loaf', 0.8178911209106445),\n",
       " ('meatball', 0.817259669303894),\n",
       " ('focaccia', 0.8139068484306335),\n",
       " ('breadcrumb', 0.812077522277832),\n",
       " ('seitan', 0.8052205443382263)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model.wv['cookie']\n",
    "model.wv.most_similar(model.wv['meat'] + model.wv['bread'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "549d23ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cake', 0.9711697697639465),\n",
       " ('icing', 0.9710375666618347),\n",
       " ('cupcake', 0.9200991988182068),\n",
       " ('frosting', 0.9078121781349182),\n",
       " ('frost', 0.9023512601852417),\n",
       " ('buttercream', 0.8940775990486145),\n",
       " ('velvet', 0.8690030574798584),\n",
       " ('decoration', 0.8613044023513794),\n",
       " ('decorate', 0.8516001105308533),\n",
       " ('fondant', 0.8395641446113586)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(model.wv['cake'] + model.wv['icing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e699b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_words = [item for sublist in df_clean['text'] for item in sublist]\n",
    "# corpus = set(all_words)\n",
    "# # word_to_ix = {word: i for i, word in enumerate(corpus)}\n",
    "\n",
    "# n_corpus = len(corpus)\n",
    "\n",
    "# all_word_counter = Counter(all_words)\n",
    "  \n",
    "# # most_common() produces k frequently encountered\n",
    "# # input values and their respective counts.\n",
    "# most_occur = all_word_counter.most_common(10)\n",
    "  \n",
    "# print(most_occur)\n",
    "# print(f\"Size of corpus: {n_corpus}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def word_list_to_vec(word_list):\n",
    "#     'return one-hot encoding of word list'\n",
    "#     vec = [0] * n_corpus\n",
    "#     for word in word_list:\n",
    "#         vec[word_to_ix[word]] = 1\n",
    "#     return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9518f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words is available in in the sklearn open source library\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebeafb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_clean['reviewText'] = df_clean.text.apply(lambda x: ' '.join(x))\n",
    "\n",
    "df_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = vectorizer.fit_transform(df_clean['reviewText'])\n",
    "# bag_of_words = vectorizer.fit_transform(lambda x: ''.join(df_clean['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ea884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(feature_names)\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4087dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "print(len(feature_names)) \n",
    "bow_df = pd.DataFrame(bag_of_words.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bow_df.head(3))\n",
    "print(bow_df.dim)\n",
    "print(bow_df.max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32861ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine_similarity generates a 2D array representing the cosine similarity from 0-1 between each text\n",
    "similarity = cosine_similarity(bag_of_words)\n",
    "# finding the max cosine similarity value in the resulting array, there are a number of built in numpy functions to get the max value but the trick is skipping the n, n index because they will always be 1\n",
    "max_value = 0\n",
    "max_x = 0\n",
    "max_y = 0\n",
    "for each_row in range(len(similarity)): \n",
    "    for each_column in range(len(similarity[0])): \n",
    "        if similarity[each_row][each_column] > max_value and each_row!=each_column:\n",
    "            max_value = similarity[each_row][each_column]\n",
    "            max_y = each_row\n",
    "            max_x = each_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b5c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44be4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_value, max_x, max_y)\n",
    "print(df.iloc[max_x])\n",
    "print(df.iloc[max_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "\n",
    "\n",
    "# Not sure about best way to use one-hot vector sv create sparese train and test matrix. Hmm.\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_clean['text'].tolist(), df_clean['overall'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1bbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=100.0, random_state=1, solver='lbfgs', multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb722233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model? Predictive vectors and then test?\n",
    "# https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bda16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9097f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e039a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_amazonei_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
