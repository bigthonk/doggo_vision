{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "checked-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler, random_split\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accessible-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hindu-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=315, scale=(0.95, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=299),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  \n",
    "    ]),\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=299),\n",
    "        transforms.CenterCrop(size=299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sitting-promise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16464 2058 2058\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "all_data = datasets.ImageFolder(root='data')\n",
    "train_data_len = int(len(all_data)*0.8)\n",
    "valid_data_len = int((len(all_data) - train_data_len)/2)\n",
    "test_data_len = int(len(all_data) - train_data_len - valid_data_len)\n",
    "train_data, val_data, test_data = random_split(all_data, [train_data_len, valid_data_len, test_data_len])\n",
    "train_data.dataset.transform = image_transforms['train']\n",
    "val_data.dataset.transform = image_transforms['test']\n",
    "test_data.dataset.transform = image_transforms['test']\n",
    "print(len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chicken-balloon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 299, 299]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "trainiter = iter(train_loader)\n",
    "features, labels = next(trainiter)\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "binary-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "         criterion,\n",
    "         optimizer,\n",
    "         train_loader,\n",
    "         val_loader,\n",
    "         save_location,\n",
    "         early_stop=2,\n",
    "         n_epochs=10,\n",
    "         print_every=1):\n",
    "\n",
    "    valid_loss_min = np.Inf\n",
    "    stop_count = 0\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "    model.epochs = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for data, label in train_loader:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            _, pred = torch.max(output, dim=1) \n",
    "            correct_tensor = pred.eq(label.data.view_as(pred)) \n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor)) \n",
    "            train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "\n",
    "        model.epochs += 1\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            for data, label in val_loader:\n",
    "                data, label = data.cuda(), label.cuda()\n",
    "\n",
    "                output = model(data)\n",
    "                loss = criterion(output, label)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, pred = torch.max(output, dim=1)\n",
    "                correct_tensor = pred.eq(label.data.view_as(pred))\n",
    "                accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "                valid_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "            train_loss = train_loss / len(train_loader.dataset)\n",
    "            valid_loss = valid_loss / len(val_loader.dataset)\n",
    "\n",
    "            train_acc = train_acc / len(train_loader.dataset)\n",
    "            valid_acc = valid_acc / len(val_loader.dataset)\n",
    "\n",
    "            history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "            if (epoch + 1) % print_every == 0:\n",
    "                print(f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}')\n",
    "                print(f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%')\n",
    "\n",
    "            if valid_loss < valid_loss_min:\n",
    "                torch.save({\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'idx_to_class': model.idx_to_class\n",
    "                }, save_location)\n",
    "                stop_count = 0\n",
    "                valid_loss_min = valid_loss\n",
    "                valid_best_acc = valid_acc\n",
    "                best_epoch = epoch\n",
    "\n",
    "            else:\n",
    "                stop_count += 1\n",
    "\n",
    "                # Below is the case where we handle the early stop case\n",
    "                if stop_count >= early_stop:\n",
    "                    print(f'\\nEarly Stopping Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%')\n",
    "                    model.load_state_dict(torch.load(save_location)['state_dict'])\n",
    "                    model.optimizer = optimizer\n",
    "                    history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_acc','valid_acc'])\n",
    "                    return model, history\n",
    "\n",
    "    model.optimizer = optimizer\n",
    "    print(f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%')\n",
    "\n",
    "    history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prescription-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model):\n",
    "    model.aux_logits=False\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    n_classes = 120\n",
    "    n_inputs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(n_inputs, n_classes),\n",
    "        nn.LogSoftmax(dim=1))\n",
    "    model.cuda()\n",
    "    model.class_to_idx = all_data.class_to_idx\n",
    "    model.idx_to_class = {\n",
    "        idx: class_\n",
    "        for class_, idx in model.class_to_idx.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alien-logistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlexNet',\n",
       " 'ConvNeXt',\n",
       " 'DenseNet',\n",
       " 'EfficientNet',\n",
       " 'GoogLeNet',\n",
       " 'GoogLeNetOutputs',\n",
       " 'Inception3',\n",
       " 'InceptionOutputs',\n",
       " 'MNASNet',\n",
       " 'MobileNetV2',\n",
       " 'MobileNetV3',\n",
       " 'RegNet',\n",
       " 'ResNet',\n",
       " 'ShuffleNetV2',\n",
       " 'SqueezeNet',\n",
       " 'VGG',\n",
       " 'VisionTransformer',\n",
       " '_GoogLeNetOutputs',\n",
       " '_InceptionOutputs',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_utils',\n",
       " 'alexnet',\n",
       " 'convnext',\n",
       " 'convnext_base',\n",
       " 'convnext_large',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'densenet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'detection',\n",
       " 'efficientnet',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'feature_extraction',\n",
       " 'googlenet',\n",
       " 'inception',\n",
       " 'inception_v3',\n",
       " 'mnasnet',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'mobilenetv2',\n",
       " 'mobilenetv3',\n",
       " 'optical_flow',\n",
       " 'quantization',\n",
       " 'regnet',\n",
       " 'regnet_x_16gf',\n",
       " 'regnet_x_1_6gf',\n",
       " 'regnet_x_32gf',\n",
       " 'regnet_x_3_2gf',\n",
       " 'regnet_x_400mf',\n",
       " 'regnet_x_800mf',\n",
       " 'regnet_x_8gf',\n",
       " 'regnet_y_128gf',\n",
       " 'regnet_y_16gf',\n",
       " 'regnet_y_1_6gf',\n",
       " 'regnet_y_32gf',\n",
       " 'regnet_y_3_2gf',\n",
       " 'regnet_y_400mf',\n",
       " 'regnet_y_800mf',\n",
       " 'regnet_y_8gf',\n",
       " 'resnet',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext50_32x4d',\n",
       " 'segmentation',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'shufflenetv2',\n",
       " 'squeezenet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'vgg',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'video',\n",
       " 'vision_transformer',\n",
       " 'vit_b_16',\n",
       " 'vit_b_32',\n",
       " 'vit_l_16',\n",
       " 'vit_l_32',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rough-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_models = [models.resnet50, models.googlenet]\n",
    "transformer_models = [models.vit_b_16, models.vit_l_16, models.vit_b_32, models.vit_l_32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "secondary-kenya",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/ec2-user/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3bfb5cfbda4e48b2fb67d3be5db55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102530333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 1 \tTraining Loss: 1.4179 \tValidation Loss: 1.2215\n",
      "\t\tTraining Accuracy: 74.11%\t Validation Accuracy: 74.98%\n",
      "\n",
      "Epoch: 3 \tTraining Loss: 0.8552 \tValidation Loss: 0.9189\n",
      "\t\tTraining Accuracy: 80.84%\t Validation Accuracy: 76.72%\n",
      "\n",
      "Epoch: 5 \tTraining Loss: 0.6843 \tValidation Loss: 0.8203\n",
      "\t\tTraining Accuracy: 83.43%\t Validation Accuracy: 78.62%\n",
      "\n",
      "Epoch: 7 \tTraining Loss: 0.5871 \tValidation Loss: 0.7470\n",
      "\t\tTraining Accuracy: 85.33%\t Validation Accuracy: 80.03%\n",
      "\n",
      "Epoch: 9 \tTraining Loss: 0.5232 \tValidation Loss: 0.7391\n",
      "\t\tTraining Accuracy: 86.72%\t Validation Accuracy: 79.30%\n",
      "\n",
      "Best epoch: 9 with loss: 0.74 and acc: 79.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 \tTraining Loss: 2.4072 \tValidation Loss: 2.0507\n",
      "\t\tTraining Accuracy: 60.14%\t Validation Accuracy: 64.29%\n",
      "\n",
      "Epoch: 3 \tTraining Loss: 1.4851 \tValidation Loss: 1.4513\n",
      "\t\tTraining Accuracy: 70.61%\t Validation Accuracy: 69.14%\n",
      "\n",
      "Epoch: 5 \tTraining Loss: 1.1876 \tValidation Loss: 1.2557\n",
      "\t\tTraining Accuracy: 73.66%\t Validation Accuracy: 70.31%\n",
      "\n",
      "Epoch: 7 \tTraining Loss: 1.0369 \tValidation Loss: 1.1586\n",
      "\t\tTraining Accuracy: 75.60%\t Validation Accuracy: 71.33%\n",
      "\n",
      "Epoch: 9 \tTraining Loss: 0.9467 \tValidation Loss: 1.0835\n",
      "\t\tTraining Accuracy: 77.38%\t Validation Accuracy: 71.87%\n",
      "\n",
      "Best epoch: 9 with loss: 1.08 and acc: 71.87%\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for model in pretrained_models:\n",
    "    model = model(pretrained=True)\n",
    "    build_model(model)\n",
    "    model, history = train(\n",
    "    model,\n",
    "    nn.NLLLoss(),\n",
    "    optim.Adam(model.parameters(), lr=0.0005),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    save_location='./dog_inception.pt',\n",
    "    early_stop=2,\n",
    "    n_epochs=10,\n",
    "    print_every=2)\n",
    "    results += [(model.__class__.__name__, model, history)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "imported-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_acc = 0\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            correct_tensor = pred.eq(label.data.view_as(pred))\n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "            test_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "        test_acc = test_acc / len(test_loader.dataset)\n",
    "        return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-inspector",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "canadian-capital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has achieved an accuracy of 72.45% on the test dataset\n"
     ]
    }
   ],
   "source": [
    "test_acc = test(model.cuda(), test_loader,  nn.NLLLoss())\n",
    "print(f'The model has achieved an accuracy of {100 * test_acc:.2f}% on the test dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modern_vision",
   "language": "python",
   "name": "modern_vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
